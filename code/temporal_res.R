# 'Multi-network Network-Based Diffusion Analysis

###########################################################################
# TEMPORAL RESOLUTION DEFINITIONS
###########################################################################

# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")

###########################################################################
# PART 1: Divide the data into different resolutions ----------------------------

## load all necessary packages
library(vegan)  
# Run multiple cores for faster computing
require(doParallel)
require(parallel)
library(sfsmisc, verbose=F)

# Read in file and add months
sample_data <- read.csv("sample_data.csv")
sample_data <- subset(sample_data, subset=c(sample_data$Code != "None"))
# Make data easily divisible
sample_data <- subset(sample_data, subset=c(sample_data$Year < 2013))

# Get all unique Code values in the entire sample_data
all_codes <- unique(sample_data$Code)

# Create a function that counts the IDs in each element
count_instances <- function(df) {
  code_counts <- table(df$Code)
  code_counts <- code_counts[match(all_codes, names(code_counts))]
  code_counts[is.na(code_counts)] <- 0
  return(code_counts)
}

# Divide resolutions from lowest to highest scale

# -------------------- 20 sets of 1 year increments----------------------------
# Make a list of only 1 year per dataframe
list_years <- split(sample_data, sample_data$Year)
# Apply the count_instances function to each year
instances_per_year <- lapply(list_years, count_instances)
# Convert the list of counts to a data frame
p1y <- do.call(rbind, instances_per_year)
# Transforming into binary matrices
p1y <- as.matrix(p1y); p1y[which(p1y>=1)] = 1; p1y[which(p1y<1)] = 0


# -------------------- 6 sets of 3 year increments----------------------------
# Make a list of 3 years per dataframe
sample_data$ThreeYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 3, by = 3), labels = FALSE)
list_threeyears <- split(sample_data, sample_data$ThreeYearIncrement)
# Apply the count_instances function to each two years
instances_per_threeyear <- lapply(list_threeyears, count_instances)
# Convert the list of counts to a data frame
p3y <- do.call(rbind, instances_per_threeyear)
# Transforming into binary matrices
p3y <- as.matrix(p3y); p3y[which(p3y>=1)] = 1; p3y[which(p3y<1)] = 0


# -------------------- 4 sets of 5 year increments----------------------------
# Make a list of 5 years per dataframe
sample_data$FiveYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 5, by = 5), labels = FALSE)
list_fiveyears <- split(sample_data, sample_data$FiveYearIncrement)
# Apply the count_instances function to each two years
instances_per_fiveyear <- lapply(list_fiveyears, count_instances)
# Convert the list of counts to a data frame
p5y <- do.call(rbind, instances_per_fiveyear)
# Transforming into binary matrices
p5y <- as.matrix(p5y); p5y[which(p5y>=1)] = 1; p5y[which(p5y<1)] = 0


# -------------------- 2 sets of 10 year increments----------------------------
# Make a list of 2 years per dataframe
sample_data$TenYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 10, by = 10), labels = FALSE)
list_tenyears <- split(sample_data, sample_data$TenYearIncrement)
# Apply the count_instances function to each two years
instances_per_tenyear <- lapply(list_tenyears, count_instances)
# Convert the list of counts to a data frame
p10y <- do.call(rbind, instances_per_tenyear)
# Transforming into binary matrices
p10y <- as.matrix(p10y); p10y[which(p10y>=1)] = 1; p10y[which(p10y<1)] = 0


###########################################################################
# PART 2: Calculate Whittaker Dissimilarity Index between Time Periods ----------------------------

source("../code/functions.R") # WDI & WDI permutation

# Turn over results
t1 = turnover_w(data = p1y, iter = 1000, subseq=F, plot=FALSE)
t3 = turnover_w(data = p3y, iter = 1000, subseq=F, plot=FALSE)
t5 = turnover_w(data = p5y, iter = 1000, subseq=F, plot=FALSE)
t10 = turnover_w(data = p10y, iter = 1000, subseq=F, plot=FALSE)

all = rbind(t1, t3, t5, t10)
all = cbind(c(1, 2, 3, 4), all)

par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 3, 5, 10), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)", 
       pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.34,0.42), xlim=c(0,10), cex.axis=0.8)
axis(1, at=c(1, 3, 5, 10),las=1, cex.axis=0.7)
mtext(side = 1, "Length of periods (years)", line = 2, font = 1)
axis(3, at=c(1, 3, 5, 10),las=1, labels=c(20,10,6,4), cex.axis=0.7)
mtext(side = 3, "Number of periods", line = 2, font = 1)

# Print final results
all

# Define the list of datasets and increment values
data_list <- list(list_years, list_twoyears, list_threeyears, list_fouryears, list_fiveyears)

# Perform the permutation test for different time period increments
n.cores <- detectCores()
system.time({
  registerDoParallel(n.cores)
  result <- wdi_permutation(data_list)
  result
  # End parallel processing
  stopImplicitCluster()
})

# Calculate 95% confidence intervals
interval <- 2

lower_ci <- quantile(result[[interval]], 0.025)
upper_ci <- quantile(result[[interval]], 0.975)

# 22 sets of 1 year increments
one_res <- mean(WDI(list_years))

# 11 sets of 2 year increments
two_res <- mean(WDI(list_twoyears))

# 7 sets of 3 year increments
three_res <- mean(WDI(list_threeyears))

# 5 sets of 4 year increments
four_res <- mean(WDI(list_fouryears))

# 4 sets of 5 year increments
five_res <- mean(WDI(list_fiveyears))


