# Specify the number of nodes/workers in the cluster
num_nodes <- 2
# Create a cluster with the specified number of nodes/workers
cl <- makeCluster(num_nodes)
# Stop the cluster
stopCluster(cl)
knitr::opts_chunk$set(echo = TRUE)
# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
## load all necessary packages
library(vegan)
# Run multiple cores for faster computing
require(doParallel)
require(parallel)
library(sfsmisc, verbose=F)
# Read in file and add months
sample_data <- read.csv("sample_data.csv")
# Get all unique Code values in the entire sample_data
all_codes <- unique(sample_data$Code)
# Create a function that counts the IDs in each element
count_instances <- function(df) {
code_counts <- table(df$Code)
code_counts <- code_counts[match(all_codes, names(code_counts))]
code_counts[is.na(code_counts)] <- 0
return(code_counts)
}
# -------------------- 22 sets of 1 year increments----------------------------
# Make a list of only 1 year per dataframe
list_years <- split(sample_data, sample_data$Year)
# Apply the count_instances function to each year
instances_per_year <- lapply(list_years, count_instances)
# Convert the list of counts to a data frame
p1y <- do.call(rbind, instances_per_year)
# Transforming into binary matrices
p1y <- as.matrix(p1y); p1y[which(p1y>=1)] = 1; p1y[which(p1y<1)] = 0
# -------------------- 11 sets of 2 year increments----------------------------
# Make a list of 2 years per dataframe
sample_data$TwoYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 2, by = 2), labels = FALSE)
list_twoyears <- split(sample_data, sample_data$TwoYearIncrement)
# Apply the count_instances function to each two years
instances_per_twoyear <- lapply(list_twoyears, count_instances)
# Convert the list of counts to a data frame
p2y <- do.call(rbind, instances_per_twoyear)
# Transforming into binary matrices
p2y <- as.matrix(p2y); p2y[which(p2y>=1)] = 1; p2y[which(p2y<1)] = 0
# -------------------- 7 sets of 3 year increments----------------------------
# Make a list of 3 years per dataframe
sample_data$ThreeYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 3, by = 3), labels = FALSE)
list_threeyears <- split(sample_data, sample_data$ThreeYearIncrement)
# Apply the count_instances function to each two years
instances_per_threeyear <- lapply(list_threeyears, count_instances)
# Convert the list of counts to a data frame
p3y <- do.call(rbind, instances_per_threeyear)
# Transforming into binary matrices
p3y <- as.matrix(p3y); p3y[which(p3y>=1)] = 1; p3y[which(p3y<1)] = 0
# -------------------- 6 sets of 4 year increments----------------------------
# Make a list of 4 years per dataframe
sample_data$FourYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 4, by = 4), labels = FALSE)
list_fouryears <- split(sample_data, sample_data$FourYearIncrement)
# Apply the count_instances function to each two years
instances_per_fouryear <- lapply(list_fouryears, count_instances)
# Convert the list of counts to a data frame
p4y <- do.call(rbind, instances_per_fouryear)
# Transforming into binary matrices
p4y <- as.matrix(p4y); p4y[which(p4y>=1)] = 1; p4y[which(p4y<1)] = 0
# -------------------- 4 sets of 5 year increments----------------------------
# Make a list of 5 years per dataframe
sample_data$FiveYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 5, by = 5), labels = FALSE)
list_fiveyears <- split(sample_data, sample_data$FiveYearIncrement)
# Apply the count_instances function to each two years
instances_per_fiveyear <- lapply(list_fiveyears, count_instances)
# Convert the list of counts to a data frame
p5y <- do.call(rbind, instances_per_fiveyear)
# Transforming into binary matrices
p5y <- as.matrix(p5y); p5y[which(p5y>=1)] = 1; p5y[which(p5y<1)] = 0
# -------------------- 4 sets of 6 year increments----------------------------
# Make a list of 6 years per dataframe
sample_data$SixYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 6, by = 6), labels = FALSE)
list_sixyears <- split(sample_data, sample_data$SixYearIncrement)
# Apply the count_instances function to each two years
instances_per_sixyear <- lapply(list_sixyears, count_instances)
# Convert the list of counts to a data frame
p6y <- do.call(rbind, instances_per_sixyear)
# Transforming into binary matrices
p6y <- as.matrix(p6y); p6y[which(p6y>=1)] = 1; p6y[which(p6y<1)] = 0
# -------------------- 3 sets of 7 year increments----------------------------
# Make a list of 7 years per dataframe
sample_data$SevenYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 7, by = 7), labels = FALSE)
list_sevenyears <- split(sample_data, sample_data$SevenYearIncrement)
# Apply the count_instances function to each two years
instances_per_sevenyear <- lapply(list_sevenyears, count_instances)
# Convert the list of counts to a data frame
p7y <- do.call(rbind, instances_per_sevenyear)
# Transforming into binary matrices
p7y <- as.matrix(p7y); p7y[which(p7y>=1)] = 1; p7y[which(p7y<1)] = 0
# -------------------- 3 sets of 8 year increments----------------------------
# Make a list of 8 years per dataframe
sample_data$EightYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 8, by = 8), labels = FALSE)
list_eightyears <- split(sample_data, sample_data$EightYearIncrement)
# Apply the count_instances function to each two years
instances_per_eightyear <- lapply(list_eightyears, count_instances)
# Convert the list of counts to a data frame
p8y <- do.call(rbind, instances_per_eightyear)
# Transforming into binary matrices
p8y <- as.matrix(p8y); p8y[which(p8y>=1)] = 1; p8y[which(p8y<1)] = 0
source("../code/functions.R") # WDI & WDI permutation
# Turn over results
t1 = turnover_w(data = p1y, iter = 1000, subseq=F, plot=FALSE)
t2 = turnover_w(data = p2y, iter = 1000, subseq=F, plot=FALSE)
t3 = turnover_w(data = p3y, iter = 1000, subseq=F, plot=FALSE)
t4 = turnover_w(data = p4y, iter = 1000, subseq=F, plot=FALSE)
t5 = turnover_w(data = p5y, iter = 1000, subseq=F, plot=FALSE)
t6 = turnover_w(data = p6y, iter = 1000, subseq=F, plot=FALSE)
t7 = turnover_w(data = p7y, iter = 1000, subseq=F, plot=FALSE)
t8 = turnover_w(data = p8y, iter = 1000, subseq=F, plot=FALSE)
all = rbind(t1, t2, t3, t4, t5, t6, t7, t8)
all = cbind(c(1, 2, 3, 4, 5, 6, 7, 8), all)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.34,0.43), xlim=c(1,8), cex.axis=0.8)
axis(1, at=c(1, 2, 3, 4, 5, 6, 7, 8),las=1, cex.axis=0.7)
mtext(side = 1, "Length of periods (years)", line = 2, font = 1)
axis(3, at=c(1, 2, 3, 4, 5, 6, 7, 8),las=1, labels=c(22, 11, 7, 6, 5, 4, 3, 3), cex.axis=0.7)
mtext(side = 3, "Number of periods", line = 2, font = 1)
# Print final results
all
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.30,0.7), xlim=c(1,8), cex.axis=0.8)
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.5,0.6), xlim=c(1,8), cex.axis=0.8)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.56,0.61), xlim=c(1,8), cex.axis=0.8)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.565,0.61), xlim=c(1,8), cex.axis=0.8)
knitr::opts_chunk$set(echo = TRUE)
# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
## load all necessary packages
library(sf) # Convert degrees to meters
library(sp) # Creates a SpatialPointsDataFrame by defining the coordinates
library(adehabitatHR) # Caluculate MCPs
library(scales) # Helps make polygons partly transparent using the alpha argument
library(ggmap) # Download tiles using ggmap
library(viridis) # Color pallette
library(gridExtra) # grid.arrange function
library(ggplot2)
library(adehabitatHR) # Kernel density
library(rgdal) # Overlap
# Read in file
sample_data <- read.csv("sample_data.csv")
# Extract coordinates
coord_data <- cbind(sample_data[,c('Date', 'StartLat', 'StartLon', 'Code', 'subYear', 'ConfHI')]) # Subset Date and Coordinates #
# Read in file
sample_data <- read.csv("sample_data.csv")
# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
# Read in file
sample_data <- read.csv("sample_data.csv")
# Read file in to retain ILV
sample_data <- read.csv("sample_data.csv")
gc()
gc()
citation("assortnet")
dbinom(0.1, 12)
dbinom(2,12,0.1)
132/2
.1^2
66*0.01*(0.9^10)
dbinom(0,12,0.1)
dbinom(12,12,0.9)
1/0
0.1^0
0.9^12
1-dbinom(1,12,0.1)
1-dbinom(1,12,0.1)-dbinom(0,12,0.1)
dpois(4,3)
ppois(2,3)
1-ppois(1,3)
1-ppois(0,3)
dpois(0,3)
1-dpois(0,3)
0.99 x 0.01/(0.01 x 0.99) + (0.02 x 0.99)
0.99 * 0.01/(0.01 * 0.99) + (0.02 * 0.99)
pois <- rpois(1000, 10)
var(pois)
nb <- rnbinom(x = 1000, size = 5, mu = 10)
nb <- rnbinom(1000, size = 5, mu = 10)
var(nb)
nb2 <- rnbinom(1000, size = 1, mu = 10)
var(nb2)
nb3 <- rnbinom(1000, size = 0.5, mu = 10)
var(nb3)
dpois(1000,10)
dpois(0,10)
dnbinom(0,5,10)
dnbinom(0,5,mu = 10)
dnbinom(0,1,mu = 10)
dnbinom(0,.5,mu = 10)
1-ppois(20, 10)
1-pnbinom(20, 5, mu = 10)
1-pnbinom(20, 1, mu = 10)
1-pnbinom(20, .5, mu = 10)
plot(dpois(pois, 10))
plot(dpois(1000, 10))
x_ppois <- seq(- 5, 1000, by = 1)
y_ppois <- ppois(x_ppois, lambda = 10)
plot(y_ppois)
x_ppois <- seq(- 5, 30, by = 1)
y_ppois <- ppois(x_ppois, lambda = 10)
plot(y_ppois)
x_nbinom <- seq(- 5, 30, by = 1)
y_nbinom <- pnbinom(x, size = 5, mu = 10)
y_nbinom <- pnbinom(x, size = 5, prob = 10)
y_nbinom <- pnbinom(x = 1000, size = 5, prob = 10)
x <- seq(0, 10, by = 1)
# Set working directory here
setwd("../data")
setwd("C:/Users/bankh/My_Repos/Dolphins/code")
# Set working directory here
setwd("../data")
# Add helpful functions
source("../code/functions.R") # edgelist function
install.packages("gridExtra")
library(igraph) # Look at Dai Shizuka/Jordi Bascompte
library(tnet) # For weights
library(sna)
library(statnet)
library(doParallel)
library(ggplot2)
library(gridExtra)
# Read in social association matrix
nxn <- readRDS("nxn.RData")
list_years <- readRDS("list_years.RData")
## Only show IDs of HI dolphins
### subset_HI in "GLMM.R"
HI_data <-  diff_raw(subset_HI(list_years))
row_names_HI <- lapply(HI_data, function (df) {
as.vector(df$Code[(df$DiffHI == "BG" | df$DiffHI == "SD" |
df$DiffHI == "FG") & df$Freq > 0])})
el <- readRDS("el_years.RData")
# Set the node names based on row names
get_names <- function (matrix, metric) {
row_names <- lapply(matrix, function (df) {rownames(df)})
for (i in seq_along(metric)) {
metric[[i]][,1] <- row_names[[i]]
}
return(metric)
}
cluster <- readRDS("cluster.RData")
cluster_diffs <- get_names(nxn, cluster)
cluster_diffs_HI <- lapply(seq_along(cluster_diffs), function(i) {
df <- cluster_diffs[[i]]
df_new <- as.data.frame(df[df[, 1] %in% row_names_HI[[i]], , drop = FALSE])
return(df_new)
})
compare_cluster <- merge(
cluster_diffs_HI[[1]][, c(1, 2)],
cluster_diffs_HI[[2]][, c(1, 2)],
by.x = "node",
by.y = "node"
)
colnames(compare_cluster) <- c("ID", "Period.1", "Period.2")
compare_cluster[, c(2, 3)] <- sapply(compare_cluster[, c(2, 3)], as.numeric)
# Calculate differences
compare_cluster$Difference <- compare_cluster$Period.2 - compare_cluster$Period.1
# Betweenness centrality
between <- lapply(el, function (df) {betweenness_w(df, alpha=1)})
between_diffs <- get_names(nxn, between)
between_diffs_HI <- lapply(seq_along(between_diffs), function(i) {
df <- between_diffs[[i]]
df_new <- as.data.frame(df[df[, 1] %in% row_names_HI[[i]], , drop = FALSE])
return(df_new)
})
compare_between <- merge(
between_diffs_HI[[1]],
between_diffs_HI[[2]],
by.x = "node",
by.y = "node"
)
colnames(compare_between) <- c("ID", "Period.1", "Period.2")
compare_between[, c(2, 3)] <- sapply(compare_between[, c(2, 3)], as.numeric)
# Calculate differences
compare_between$Difference <- compare_between$Period.2 - compare_between$Period.1
# Closeness centrality
close <- lapply(el, function (df) {closeness_w(df, alpha=1)})
close_diffs <- get_names(nxn, close)
close_diffs_HI <- lapply(seq_along(close_diffs), function(i) {
df <- close_diffs[[i]]
df_new <- as.data.frame(df[df[, 1] %in% row_names_HI[[i]], , drop = FALSE])
return(df_new)
})
compare_close <- merge(
close_diffs_HI[[1]][, c(1, 2)],
close_diffs_HI[[2]][, c(1, 2)],
by.x = "node",
by.y = "node"
)
colnames(compare_close) <- c("ID", "Period.1", "Period.2")
compare_close[, c(2, 3)] <- sapply(compare_close[, c(2, 3)], as.numeric)
# Calculate differences
compare_close$Difference <- compare_close$Period.2 - compare_close$Period.1
# Degree and strength centrality
strength <- lapply(el, function (df) {degree_w(df, measure=c("degree","output"), type="out", alpha=1)})
strength_diffs <- get_names(nxn, strength)
strength_diffs_HI <- lapply(seq_along(strength_diffs), function(i) {
df <- strength_diffs[[i]]
df_new <- as.data.frame(df[df[, 1] %in% row_names_HI[[i]], , drop = FALSE])
return(df_new)
})
compare_strength <- merge(
strength_diffs_HI[[1]],
strength_diffs_HI[[2]],
by.x = "node",
by.y = "node"
)
colnames(compare_strength) <- c("ID", "Period.1_degree", "Period.1_strength", "Period.2_degree", "Period.2_strength")
compare_strength[, c(2:5)] <- sapply(compare_strength[, c(2:5)], as.numeric)
# Calculate differences
compare_strength$Difference_degree <- compare_strength$Period.2_degree - compare_strength$Period.1_degree
compare_strength$Difference_strength <- compare_strength$Period.2_strength - compare_strength$Period.1_strength
# Look at all of the local metrics together
## Add a column containing HI type
names_BG <- unlist(lapply(HI_data, function (df) {
as.vector(df$Code[df$DiffHI == "BG" & df$Freq > 0])}))
names_SD <- unlist(lapply(HI_data, function (df) {
as.vector(df$Code[df$DiffHI == "SD" & df$Freq > 0])}))
names_FG <- unlist(lapply(HI_data, function (df) {
as.vector(df$Code[df$DiffHI == "FG" & df$Freq > 0])}))
HI_type <- ifelse(compare_cluster$ID %in% names_BG, "BG",
ifelse(compare_cluster$ID %in% names_SD, "SD",
ifelse(compare_cluster$ID %in% names_FG, "FG", "NA")))
# Combine the data
local_metrics_HI <- data.frame(ID = compare_cluster$ID, HI_type = HI_type,
Period = c("Period.1", "Period.2"),
Cluster = c(compare_cluster$Period.1, compare_cluster$Period.2),
Between = c(compare_between$Period.1, compare_between$Period.2),
Close = c(compare_close$Period.1, compare_close$Period.2),
Degree = c(compare_strength$Period.1_degree, compare_strength$Period.2_degree),
Strength = c(compare_strength$Period.1_strength, compare_strength$Period.2_strength))
## Add a rown to compare the averages of each metric with HI IDs
avg_metrics <- data.frame(ID = "Average", HI_type = "NA",
Period = c("Period.1", "Period.2"),
Cluster = c(mean(cluster[[2]][, 2]), mean(cluster[[1]][, 2])),
Between = c(mean(between[[2]][, 2]), mean(between[[1]][, 2])),
Close = c(mean(close[[2]][, 2]), mean(close[[1]][, 2])),
Degree = c(mean(strength[[2]][, 2]), mean(strength[[1]][, 2])),
Strength = c(mean(strength[[2]][, 3]), mean(strength[[1]][, 3])))
local_metrics_HI <- rbind(local_metrics_HI, avg_metrics)
# Reshape the data from wide to long format
local_metrics_HI <- melt(local_metrics_HI, id.vars = c("ID", "HI_type", "Period"), variable.name = "Metric")
library(reshape)
# Reshape the data from wide to long format
local_metrics_HI <- melt(local_metrics_HI, id.vars = c("ID", "HI_type", "Period"), variable.name = "Metric")
# Make sure metric is in character
local_metrics_HI$Metric <- as.character(local_metrics_HI$Metric)
local_metrics_HI
str(local_metrics_HI)
colnames(local_metrics_HI) <- c("ID", "HI_type", "Period", "Metric", "value")
# Make sure metric is in character
local_metrics_HI$Metric <- as.character(local_metrics_HI$Metric)
# Get rid of the average values
local_met_HI <- local_metrics_HI[local_metrics_HI$HI_type != "NA", ]
metric <- "Cluster"
# Filter data for the current metric
metric_data <- local_met_HI[local_met_HI$Metric == metric,]
metric_data
# Get the corresponding value for NA, Period.1 and the current metric
value_na_period1 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.1" &
local_metrics_HI$Metric == metric]
# Get the corresponding value for NA, Period.2 and the current metric
value_na_period2 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.2" &
local_metrics_HI$Metric == metric]
# Create the plot
ggplot(metric_data, aes(x = HI_type, y = value, fill = Period)) +
geom_boxplot(position = "identity", alpha = 0.5) +
labs(x = "HI Type", y = NULL, fill = "Period") +
ggtitle(paste(metric)) +
theme(panel.background = element_blank()) +
geom_hline(yintercept = value_na_period1, col = "red", linetype = "dashed") +
geom_hline(yintercept = value_na_period2, col = "blue", linetype = "dashed")
seq_along(unique(local_met_HI$Metric)
seq_along(unique(local_met_HI$Metric))
# Plot for each Metric
plot_list <- list()
for (i in seq_along(unique(local_met_HI$Metric))) {
for (metric in unique(local_met_HI$Metric)) {
# Filter data for the current metric
metric_data <- local_met_HI[local_met_HI$Metric == metric,]
# Get the corresponding value for NA, Period.1 and the current metric
value_na_period1 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.1" &
local_metrics_HI$Metric == metric]
# Get the corresponding value for NA, Period.2 and the current metric
value_na_period2 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.2" &
local_metrics_HI$Metric == metric]
# Create the plot
plot_list[[i]] <- ggplot(metric_data, aes(x = HI_type, y = value, fill = Period)) +
geom_boxplot(position = "identity", alpha = 0.5) +
labs(x = "HI Type", y = NULL, fill = "Period") +
ggtitle(paste(metric)) +
theme(panel.background = element_blank()) +
geom_hline(yintercept = value_na_period1, col = "red", linetype = "dashed") +
geom_hline(yintercept = value_na_period2, col = "blue", linetype = "dashed")
}
}
plot_list[[1]]
plot_list[[2]]
# Get rid of the average values
local_met_HI <- local_metrics_HI[local_metrics_HI$HI_type != "NA", ]
# Plot for each Metric
plot_list <- list()
unique_metrics <- unique(local_met_HI$Metric)
for (i in seq_along(unique_metrics)) {
metric <- unique_metrics[i]
# Filter data for the current metric
metric_data <- local_met_HI[local_met_HI$Metric == metric,]
# Get the corresponding value for NA, Period.1 and the current metric
value_na_period1 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.1" &
local_metrics_HI$Metric == metric]
# Get the corresponding value for NA, Period.2 and the current metric
value_na_period2 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.2" &
local_metrics_HI$Metric == metric]
# Create the plot
plot_list[[i]] <- ggplot(metric_data, aes(x = HI_type, y = value, fill = Period)) +
geom_boxplot(position = "identity", alpha = 0.5) +
labs(x = "HI Type", y = NULL, fill = "Period") +
ggtitle(paste(metric)) +
theme(panel.background = element_blank()) +
geom_hline(yintercept = value_na_period1, col = "red", linetype = "dashed") +
geom_hline(yintercept = value_na_period2, col = "blue", linetype = "dashed")
}
# Arrange plots side by side
grid.arrange(grobs = plot_list, ncol = 5)
# Plot for each Metric
plot_list <- list()
unique_metrics <- unique(local_met_HI$Metric)
# Create a flag to keep track of the first plot for legend extraction
first_plot <- TRUE
for (i in seq_along(unique_metrics)) {
metric <- unique_metrics[i]
# Filter data for the current metric
metric_data <- local_met_HI[local_met_HI$Metric == metric,]
# Get the corresponding value for NA, Period.1 and the current metric
value_na_period1 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.1" &
local_metrics_HI$Metric == metric]
# Get the corresponding value for NA, Period.2 and the current metric
value_na_period2 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.2" &
local_metrics_HI$Metric == metric]
# Create the plot
current_plot <- ggplot(metric_data, aes(x = HI_type, y = value, fill = Period)) +
geom_boxplot(position = "identity", alpha = 0.5) +
labs(x = "HI Type", y = NULL, fill = "Period") +
ggtitle(paste(metric)) +
theme(panel.background = element_blank()) +
geom_hline(yintercept = value_na_period1, col = "red", linetype = "dashed") +
geom_hline(yintercept = value_na_period2, col = "blue", linetype = "dashed")
# Extract legend from the first plot and remove it from subsequent plots
if (first_plot) {
plot_list[[i]] <- current_plot
first_plot <- FALSE
} else {
plot_list[[i]] <- current_plot + theme(legend.position = "none")
}
}
# Arrange plots side by side
grid.arrange(grobs = plot_list, ncol = 5)
# Plot for each Metric
plot_list <- list()
unique_metrics <- unique(local_met_HI$Metric)
for (i in seq_along(unique_metrics)) {
metric <- unique_metrics[i]
# Filter data for the current metric
metric_data <- local_met_HI[local_met_HI$Metric == metric,]
# Get the corresponding value for NA, Period.1 and the current metric
value_na_period1 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.1" &
local_metrics_HI$Metric == metric]
# Get the corresponding value for NA, Period.2 and the current metric
value_na_period2 <- local_metrics_HI$value[local_metrics_HI$HI_type == "NA" &
local_metrics_HI$Period == "Period.2" &
local_metrics_HI$Metric == metric]
# Create the plot
current_plot <- ggplot(metric_data, aes(x = HI_type, y = value, fill = Period)) +
geom_boxplot(position = "identity", alpha = 0.5) +
labs(x = "HI Type", y = NULL, fill = "Period") +
ggtitle(paste(metric)) +
theme(panel.background = element_blank()) +
geom_hline(yintercept = value_na_period1, col = "red", linetype = "dashed") +
geom_hline(yintercept = value_na_period2, col = "blue", linetype = "dashed")
# Store the legend on the last plot
if (i == length(unique_metrics)) {
plot_list[[i]] <- current_plot + theme(legend.position = "bottom")
} else {
plot_list[[i]] <- current_plot + theme(legend.position = "none")
}
}
# Arrange plots side by side
grid.arrange(grobs = plot_list, ncol = 5)
