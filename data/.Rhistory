E(igrand)$weight <- sample(E(igrand)$weight)
## Calculate modularity Q-value
rmod <- walktrap.community(igrand)
modularity(rmod)
## Number of modules
groups(rmod)
# Difference from our empirical data?
modularity(dolphin_walk[[year]])
# Run modularity permutations 1000 times
iter = 1000
randmod = numeric()
for(i in 1:iter){
# Save the edgelist into a new object
auxrand <- el[[year]]
# igraph format
igrand <- graph.edgelist(auxrand[,1:2]) # Create a network from the list of nodes
E(igrand)$weight <- auxrand[,2] # Add link weights
igrand <- as.undirected(igrand) # Make undirected graph
# Permutate the link weights
E(igrand)$weight <- sample(E(igrand)$weight)
# calculate the modularity Q-value
rand_walk <- walktrap.community(igrand)
randmod[i] <- modularity(rand_walk) # Save Q-value into a vector
}
## Calculate the 95% confidence interval (two-tailed test)
ci = quantile(randmod, probs=c(0.025, 0.975), type=2)
## Compare with the empirical Q-value
data.frame(Q=modularity(dolphin_walk[[year]]), LowCI=ci[1], HighCI=ci[2])
## Visualization random Q distribution
hist(randmod, xlim=c(0,0.6))
### Empirical Q-value
abline(v= modularity(dolphin_walk[[year]]), col="red")
### 2.5% CI
abline(v= ci[1], col="blue")
### 97.5% CI
abline(v= ci[2], col="blue")
# Create an unweighted network
system.time({
registerDoParallel(n.cores)
dolp_ig <- list()
for (l in 1:length(years)) {
dolp_ig[[l]] <- graph.edgelist(el[[l]][,1:2])
# Add the edge weights to this network
E(dolp_ig[[l]])$weight <- as.numeric(el[[l]][,3])
# Create undirected network
dolp_ig[[l]] <- as.undirected(dolp_ig[[l]])
}
### End parallel processing
stopImplicitCluster()
})
# Create an unweighted network
system.time({
registerDoParallel(n.cores)
dolp_ig <- list()
for (l in seq_along(list_years)) {
dolp_ig[[l]] <- graph.edgelist(el[[l]][,1:2])
# Add the edge weights to this network
E(dolp_ig[[l]])$weight <- as.numeric(el[[l]][,3])
# Create undirected network
dolp_ig[[l]] <- as.undirected(dolp_ig[[l]])
}
### End parallel processing
stopImplicitCluster()
})
# Newman's Q modularity
newman <- cluster_leading_eigen(dolp_ig[[year]], steps = -1, weights = E(dolp_ig[[year]])$weight,
start = NULL, options = arpack_defaults, callback = NULL,
extra = NULL, env = parent.frame())
# Generate a vector of colors based on the number of unique memberships
V(dolp_ig[[year]])$color <- NA
col <- rainbow(max(newman$membership))
# Create a vector of individual IDs
individual_ids <- 1:vcount(dolp_ig[[year]])
# Assign individual IDs as labels to the nodes
V(dolp_ig[[year]])$label <- individual_ids
for (i in 1:max(newman$membership)){
V(dolp_ig[[year]])$color[which(newman$membership==i)] <- col[i]
}
# Plot the graph with individual IDs as labels
plot(dolp_ig[[year]], vertex.label = V(dolp_ig[[year]])$label)
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
## Extract IDs and coordinates
ids <- human_data$Code
coordinates <- human_data[, c("StartLon", "StartLat")]
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids)
View(coordinates)
# Convert to data frame
ids_df <- data.frame(id = ids)
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids_df)
# Set CRS and transform to UTM
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
coords_sp_utm <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
library(sf) # Convert degrees to meters
library(sp) # Creates a SpatialPointsDataFrame by defining the coordinates
library(adehabitatHR) # Caluculate MCPs and Kernel density
library(scales) # Helps make polygons partly transparent using the alpha argument
library(ggmap) # Download tiles using ggmap
library(viridis) # Color pallette
library(gridExtra) # grid.arrange function
library(ggplot2)
library(rgdal) #
library(sf) # Convert degrees to meters
library(sp) # Creates a SpatialPointsDataFrame by defining the coordinates
library(adehabitatHR) # Caluculate MCPs and Kernel density
library(scales) # Helps make polygons partly transparent using the alpha argument
library(ggmap) # Download tiles using ggmap
library(viridis) # Color pallette
library(gridExtra) # grid.arrange function
library(ggplot2)
library(rgdal) #
# Calculate kernel values
kernel <- kernelUD(coords_sp, h = 10000)
# Eliminate IDs with less than 5 locations
sub_locations <- function(human_data) {
updated_list_years <- list()  # Initialize an empty list to store the updated datasets
for (i in seq_along(human_data)) {
ID <- unique(human_data[[i]]$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(human_data[[i]]$Code == ID[j])
}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 10)
updated_list_years[[i]] <- subset(human_data[[i]], Code %in% sub$ID)
}
return(updated_list_years)
}
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
# Eliminate IDs with less than 5 locations
sub_locations <- function(h_data) {
updated_list_years <- list()  # Initialize an empty list to store the updated datasets
for (i in seq_along(h_data)) {
ID <- unique(h_data[[i]]$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(h_data[[i]]$Code == ID[j])
}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
updated_list_years[[i]] <- subset(h_data[[i]], Code %in% sub$ID)
}
return(updated_list_years)
}
human_data <- sub_locations(human_data)
# Eliminate IDs with less than 5 locations
ID <- unique(human_data$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(human_data$Code == ID[j])
}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
human_data <- subset(human_data[[i]], Code %in% sub$ID)
human_data <- subset(human_data, ID %in% sub$ID)
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
# Eliminate IDs with less than 5 locations
ID <- unique(human_data$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(human_data$Code == ID[j])
}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
human_data <- subset(human_data, ID %in% sub$ID)
sub
View(human_data)
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
# Eliminate IDs with less than 5 locations
ID <- unique(human_data$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(human_data$Code == ID[j])
}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
human_data <- subset(human_data, Code %in% sub$ID)
## Extract IDs and coordinates
ids <- human_data$Code
coordinates <- human_data[, c("StartLon", "StartLat")]
# Convert to data frame
ids_df <- data.frame(id = ids)
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids_df)
# Set CRS and transform to UTM
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
coords_sp_utm <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
# Calculate kernel values
kernel <- kernelUD(coords_sp, h = 10000)
View(kernel)
# Human activity
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
line_data <- subset(human_data, subset=c(human_data$X.Lines > 0))
pot_data <- subset(human_data, subset=c(human_data$X.CrabPots > 0))
# Seperate each number of boats into their own row
boat_data_test <- boat_data[rep(1:nrow(boat_data), boat_data$X.Boats), , drop = FALSE]
View(boat_data)
View(boat_data_test)
# Add a row identifier for each boat
boat_data_test$BoatID <- sequence(boat_data$X.Boats)
# Drop the original X.Boats column
boat_data_test <- boat_data_test[, -1]
install.packages("dplyr")
install.packages("dplyr")
install.packages("tidyr")
library(dplyr)
library(tidyr)
# Seperate each number of boats into their own row
boat_data <- boat_data %>%
mutate(X.Boats = as.numeric(X.Boats)) %>%
group_by(X.Boats) %>%
slice(rep(1:n(), X.Boats)) %>%
ungroup() %>%
mutate(BoatID = row_number()) %>%
select(BoatID, X.Boats) %>%
arrange(BoatID)
# Human activity
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
# Seperate each number of boats into their own row
boat_data_test <- boat_data %>%
mutate(X.Boats = as.numeric(X.Boats)) %>%
group_by(X.Boats) %>%
slice(rep(1:n(), X.Boats)) %>%
ungroup() %>%
mutate(BoatID = row_number()) %>%
select(BoatID, X.Boats) %>%
arrange(BoatID)
View(boat_data)
View(boat_data_test)
# Human activity
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
# Seperate each number of boats into their own row
boat_data_split <- boat_data %>%
mutate(X.Boats = as.numeric(X.Boats)) %>%
group_by(X.Boats) %>%
slice(rep(1:n(), X.Boats)) %>%
ungroup() %>%
mutate(BoatID = row_number()) %>%
select(BoatID, X.Boats) %>%
arrange(BoatID)
View(boat_data_split)
# Combine the split and expanded data with the original data
combined_data <- bind_rows(list(OriginalData = boat_data, ExpandedData = boat_data_split), .id = "DataType")
View(combined_data)
# Human activity
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
# Seperate each number of boats into their own row
boat_data_split <- boat_data %>%
slice(rep(1:n(), times = boat_data$X.Boats))
View(boat_data_split)
line_data_split <- line_data %>%
slice(rep(1:n(), times = line_data$X.Lines))
pot_data_split <- pot_data %>%
slice(rep(1:n(), times = pot_data$X.CrabPots))
View(pot_data_split)
# Calculate kernel values
create_kd <- function(df) {
## Extract IDs and coordinates
ids <- df$Code
coordinates <- df[, c("StartLon", "StartLat")]
# Convert to data frame
ids_df <- data.frame(id = ids)
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids_df)
# Set CRS and transform to UTM
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
coords_sp_utm <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
# Calculate kernel values
kernel <- kernelUD(coords_sp, h = 10000)
return(kernel)
}
# Make a kernel density of each human activity
kernel_boat <- create_kd(boat_data_split)
## load all necessary packages
library(sf) # Convert degrees to meters
library(sp) # Creates a SpatialPointsDataFrame by defining the coordinates
library(adehabitatHR) # Caluculate MCPs and Kernel density
library(scales) # Helps make polygons partly transparent using the alpha argument
library(ggmap) # Download tiles using ggmap
library(viridis) # Color pallette
library(gridExtra) # grid.arrange function
library(ggplot2)
library(rgdal) # Overlap
# Make a kernel density of each human activity
kernel_boat <- create_kd(boat_data_split)
homerange_kernel <- create_kd(human_data)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
human_data <- relocate_lim(human_data)
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- row_number(boat_data_split)
View(boat_data_split)
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- 1:nrow(boat_data_split)
View(boat_data_split)
line_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Lines))
line_data_split$ID <- 1:nrow(line_data_split)
pot_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.CrabPots))
pot_data_split$ID <- 1:nrow(pot_data_split)
# Calculate kernel values
create_kd <- function(df, ID) {
## Extract IDs and coordinates
ids <- df$ID
coordinates <- df[, c("StartLon", "StartLat")]
# Convert to data frame
ids_df <- data.frame(id = ids)
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids_df)
# Set CRS and transform to UTM
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
coords_sp_utm <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
# Calculate kernel values
kernel <- kernelUD(coords_sp, h = 10000)
return(kernel)
}
# Eliminate IDs with less than 5 locations
boat_data <- relocate_lim(boat_data)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df, code) {
ID <- unique(df$code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
# Subset data
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
# Subset data
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
line_data <- subset(human_data, subset=c(human_data$X.Lines > 0))
pot_data <- subset(human_data, subset=c(human_data$X.CrabPots > 0))
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
library(tidyr)
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
library(dplyr)
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- 1:nrow(boat_data_split)
line_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Lines))
line_data_split$ID <- 1:nrow(line_data_split)
pot_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.CrabPots))
pot_data_split$ID <- 1:nrow(pot_data_split)
# Eliminate IDs with less than 5 locations
boat_data_split <- relocate_lim(boat_data_split)
line_data_split <- relocate_lim(line_data_split)
pot_data_split <- relocate_lim(pot_data_split)
# Make a kernel density of each human activity
kernel_boat <- create_kd(boat_data_split, ID)
# Subset data
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
line_data <- subset(human_data, subset=c(human_data$X.Lines > 0))
pot_data <- subset(human_data, subset=c(human_data$X.CrabPots > 0))
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- 1:nrow(boat_data_split)
line_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Lines))
line_data_split$ID <- 1:nrow(line_data_split)
pot_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.CrabPots))
pot_data_split$ID <- 1:nrow(pot_data_split)
# Eliminate IDs with less than 5 locations
boat_data_split <- relocate_lim(boat_data_split, ID)
# Subset data
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
line_data <- subset(human_data, subset=c(human_data$X.Lines > 0))
pot_data <- subset(human_data, subset=c(human_data$X.CrabPots > 0))
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- 1:nrow(boat_data_split)
line_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Lines))
line_data_split$ID <- 1:nrow(line_data_split)
pot_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.CrabPots))
pot_data_split$ID <- 1:nrow(pot_data_split)
# Eliminate IDs with less than 5 locations
boat_data_split <- relocate_lim(boat_data_split, boat_data_split$ID)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df, id) {
ID <- unique(df$id)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$id == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, id %in% sub$ID)
}
human_data <- relocate_lim(human_data, Code)
# Subset the data that contains human activity
human_data <- subset(sample_data, subset=c(sample_data$Year > 2012))
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$Code)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
human_data <- relocate_lim(human_data)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$ID)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
boat_data_split <- relocate_lim(boat_data_split)
# Subset data
boat_data <- subset(human_data, subset=c(human_data$X.Boats > 0))
line_data <- subset(human_data, subset=c(human_data$X.Lines > 0))
pot_data <- subset(human_data, subset=c(human_data$X.CrabPots > 0))
# Seperate each number of boats into their own row
boat_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Boats))
boat_data_split$ID <- 1:nrow(boat_data_split)
line_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.Lines))
line_data_split$ID <- 1:nrow(line_data_split)
pot_data_split <- human_data %>%
slice(rep(1:n(), times = human_data$X.CrabPots))
pot_data_split$ID <- 1:nrow(pot_data_split)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$ID)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$Code == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, Code %in% sub$ID)
}
boat_data_split <- relocate_lim(boat_data_split)
line_data_split <- relocate_lim(line_data_split)
pot_data_split <- relocate_lim(pot_data_split)
# Eliminate IDs with less than 5 locations
relocate_lim <- function(df) {
ID <- unique(df$ID)
obs_vect <- numeric(length(ID))
for (j in seq_along(ID)) {
obs_vect[j] <- sum(df$ID == ID[j])}
sub <- data.frame(ID = ID, obs_vect = obs_vect)
sub <- subset(sub, subset = obs_vect > 5)
df <- subset(df, ID %in% sub$ID)
}
boat_data_split <- relocate_lim(boat_data_split)
line_data_split <- relocate_lim(line_data_split)
pot_data_split <- relocate_lim(pot_data_split)
# Make a kernel density of each human activity
create_kd <- function(df) {
## Extract IDs and coordinates
ids <- df$ID
coordinates <- df[, c("StartLon", "StartLat")]
# Convert to data frame
ids_df <- data.frame(id = ids)
# Create a SpatialPointsDataFrame with coordinates
coords_sp <- SpatialPointsDataFrame(coords = coordinates, data = ids_df)
# Set CRS and transform to UTM
proj4string(coords_sp) <- CRS("+proj=longlat +datum=WGS84")
coords_sp_utm <- spTransform(coords_sp, CRS("+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"))
# Calculate kernel values
kernel <- kernelUD(coords_sp, h = 10000)
return(kernel)
}
kernel_boat <- create_kd(boat_data_split)
