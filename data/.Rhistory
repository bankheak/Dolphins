tmp<-veg.dynamics_vect(N.suitable=N.suitable,N.unsuit=N.unsuit,time=time,
hurricane=hurricane)
N.suitable=tmp[,1]
N.unsuit=tmp[,2]
time=tmp[,3]
# restore 5 patches decision
N.suitable=ifelse(decis==3, N.suitable+5, N.suitable)
Total.ptch = N.suitable+N.unsuit
}
occ.states<-ifelse(is.na(occ.states),0,occ.states)
return(occ.states)
}
dec.1<-mouse.patch.dyn_vect(N.suitable=rep(50, 1e4),N.unsuit=rep(50,1e4),
years= 50, decision=rep(1, 1e4))
dec.1
# Change Persistence
change.persistence_vect<-function(decision, hurricane){
p.persist.hat<- 0.75
p.persist.var<- 0.05
cur.per.beta<-beta.mom(p.persist.hat,p.persist.var)
p.persist.curr<-rbeta(length(hurricane),cur.per.beta[1],cur.per.beta[2])
if (decision==2){
ln.odds<- log(p.persist.curr/(1-p.persist.curr))
change<- rnorm(length(hurricane),1.3,0.17)
p.persist<- 1/(1+exp(-(ln.odds*change)))
} else p.persist <- p.persist.curr
p.persist<-ifelse(hurricane==1, 0.3,p.persist)
return(p.persist)
}
# Change persistence
change.persistence_vect<-function(decision, hurricane){
p.persist.hat<- 0.75
p.persist.var<- 0.05
cur.per.beta<-beta.mom(p.persist.hat,p.persist.var)
p.persist.curr<-rbeta(1,cur.per.beta[1],cur.per.beta[2])
if (decision==2){
ln.odds<- log(p.persist.curr/(1-p.persist.curr))
change<- rnorm(length(hurricane),1.3,0.17)
p.persist<- 1/(1+exp(-(ln.odds*change)))
} else p.persist <- p.persist.curr
p.persist<-ifelse(hurricane==1, 0.3,p.persist)
return(p.persist)
}
#' Mouse dynamics function
mouse.patch.dyn_vect<-function(N.suitable,N.unsuit,years,decision){
# set initial values
p.colon.hat<- 0.5
p.colon.var<- 0.1
beta.colon<-beta.mom(p.colon.hat,p.colon.var)
p.persist.hat=0.75
time=0
# initial occupancy
occ.states<-initial_occup_vect(p.persist=p.persist.hat,p.colon=p.colon.hat, N.suitable=N.suitable)
# place to hold proportion occupied
for(yr in 1:years){
# implement decision in year 5
decis<- ifelse(yr==5,decision,1)
hurricane<-rbinom(length(N.suitable),1,0.02)
p.persist=change.persistence_vect(decision=decis,hurricane=hurricane)
p.colon<-rbeta(length(N.suitable),beta.colon[1],beta.colon[2])
# if nothing is occupied colonization is zero
p.colon<-ifelse(occ.states > 0,p.colon,0)
occ.states<- colon_extinct_vect(p.persist=p.persist,N.occupied.t=occ.states,
p.colon=p.colon, N.empty.t=(N.suitable-occ.states))
tmp<-veg.dynamics_vect(N.suitable=N.suitable,N.unsuit=N.unsuit,time=time,
hurricane=hurricane)
N.suitable=tmp[,1]
N.unsuit=tmp[,2]
time=tmp[,3]
# restore 5 patches decision
N.suitable=ifelse(decis==3, N.suitable+5, N.suitable)
Total.ptch = N.suitable+N.unsuit
}
occ.states<-ifelse(is.na(occ.states),0,occ.states)
return(occ.states)
}
dec.1<-mouse.patch.dyn_vect(N.suitable=rep(50, 1e4),N.unsuit=rep(50,1e4),
years= 50, decision=rep(1, 1e4))
dec.1
dec.1<-mouse.patch.dyn_vect(N.suitable=rep(50, 1e4),N.unsuit=rep(50,1e4),
years= 50, decision=rep(1, 1e4))
dec.1
vect <- rnorm(100, 30, 2)
# Stop the cluster
stopCluster(cl)
library(parallel)
library(doParallel)
# Stop the cluster
stopCluster(cl)
stopImplicitCluster()
# Specify the number of nodes/workers in the cluster
num_nodes <- 2
# Create a cluster with the specified number of nodes/workers
cl <- makeCluster(num_nodes)
# Stop the cluster
stopCluster(cl)
knitr::opts_chunk$set(echo = TRUE)
# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
## load all necessary packages
library(vegan)
# Run multiple cores for faster computing
require(doParallel)
require(parallel)
library(sfsmisc, verbose=F)
# Read in file and add months
sample_data <- read.csv("sample_data.csv")
# Get all unique Code values in the entire sample_data
all_codes <- unique(sample_data$Code)
# Create a function that counts the IDs in each element
count_instances <- function(df) {
code_counts <- table(df$Code)
code_counts <- code_counts[match(all_codes, names(code_counts))]
code_counts[is.na(code_counts)] <- 0
return(code_counts)
}
# -------------------- 22 sets of 1 year increments----------------------------
# Make a list of only 1 year per dataframe
list_years <- split(sample_data, sample_data$Year)
# Apply the count_instances function to each year
instances_per_year <- lapply(list_years, count_instances)
# Convert the list of counts to a data frame
p1y <- do.call(rbind, instances_per_year)
# Transforming into binary matrices
p1y <- as.matrix(p1y); p1y[which(p1y>=1)] = 1; p1y[which(p1y<1)] = 0
# -------------------- 11 sets of 2 year increments----------------------------
# Make a list of 2 years per dataframe
sample_data$TwoYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 2, by = 2), labels = FALSE)
list_twoyears <- split(sample_data, sample_data$TwoYearIncrement)
# Apply the count_instances function to each two years
instances_per_twoyear <- lapply(list_twoyears, count_instances)
# Convert the list of counts to a data frame
p2y <- do.call(rbind, instances_per_twoyear)
# Transforming into binary matrices
p2y <- as.matrix(p2y); p2y[which(p2y>=1)] = 1; p2y[which(p2y<1)] = 0
# -------------------- 7 sets of 3 year increments----------------------------
# Make a list of 3 years per dataframe
sample_data$ThreeYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 3, by = 3), labels = FALSE)
list_threeyears <- split(sample_data, sample_data$ThreeYearIncrement)
# Apply the count_instances function to each two years
instances_per_threeyear <- lapply(list_threeyears, count_instances)
# Convert the list of counts to a data frame
p3y <- do.call(rbind, instances_per_threeyear)
# Transforming into binary matrices
p3y <- as.matrix(p3y); p3y[which(p3y>=1)] = 1; p3y[which(p3y<1)] = 0
# -------------------- 6 sets of 4 year increments----------------------------
# Make a list of 4 years per dataframe
sample_data$FourYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 4, by = 4), labels = FALSE)
list_fouryears <- split(sample_data, sample_data$FourYearIncrement)
# Apply the count_instances function to each two years
instances_per_fouryear <- lapply(list_fouryears, count_instances)
# Convert the list of counts to a data frame
p4y <- do.call(rbind, instances_per_fouryear)
# Transforming into binary matrices
p4y <- as.matrix(p4y); p4y[which(p4y>=1)] = 1; p4y[which(p4y<1)] = 0
# -------------------- 4 sets of 5 year increments----------------------------
# Make a list of 5 years per dataframe
sample_data$FiveYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 5, by = 5), labels = FALSE)
list_fiveyears <- split(sample_data, sample_data$FiveYearIncrement)
# Apply the count_instances function to each two years
instances_per_fiveyear <- lapply(list_fiveyears, count_instances)
# Convert the list of counts to a data frame
p5y <- do.call(rbind, instances_per_fiveyear)
# Transforming into binary matrices
p5y <- as.matrix(p5y); p5y[which(p5y>=1)] = 1; p5y[which(p5y<1)] = 0
# -------------------- 4 sets of 6 year increments----------------------------
# Make a list of 6 years per dataframe
sample_data$SixYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 6, by = 6), labels = FALSE)
list_sixyears <- split(sample_data, sample_data$SixYearIncrement)
# Apply the count_instances function to each two years
instances_per_sixyear <- lapply(list_sixyears, count_instances)
# Convert the list of counts to a data frame
p6y <- do.call(rbind, instances_per_sixyear)
# Transforming into binary matrices
p6y <- as.matrix(p6y); p6y[which(p6y>=1)] = 1; p6y[which(p6y<1)] = 0
# -------------------- 3 sets of 7 year increments----------------------------
# Make a list of 7 years per dataframe
sample_data$SevenYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 7, by = 7), labels = FALSE)
list_sevenyears <- split(sample_data, sample_data$SevenYearIncrement)
# Apply the count_instances function to each two years
instances_per_sevenyear <- lapply(list_sevenyears, count_instances)
# Convert the list of counts to a data frame
p7y <- do.call(rbind, instances_per_sevenyear)
# Transforming into binary matrices
p7y <- as.matrix(p7y); p7y[which(p7y>=1)] = 1; p7y[which(p7y<1)] = 0
# -------------------- 3 sets of 8 year increments----------------------------
# Make a list of 8 years per dataframe
sample_data$EightYearIncrement <- cut(sample_data$Year, breaks = seq(min(sample_data$Year), max(sample_data$Year) + 8, by = 8), labels = FALSE)
list_eightyears <- split(sample_data, sample_data$EightYearIncrement)
# Apply the count_instances function to each two years
instances_per_eightyear <- lapply(list_eightyears, count_instances)
# Convert the list of counts to a data frame
p8y <- do.call(rbind, instances_per_eightyear)
# Transforming into binary matrices
p8y <- as.matrix(p8y); p8y[which(p8y>=1)] = 1; p8y[which(p8y<1)] = 0
source("../code/functions.R") # WDI & WDI permutation
# Turn over results
t1 = turnover_w(data = p1y, iter = 1000, subseq=F, plot=FALSE)
t2 = turnover_w(data = p2y, iter = 1000, subseq=F, plot=FALSE)
t3 = turnover_w(data = p3y, iter = 1000, subseq=F, plot=FALSE)
t4 = turnover_w(data = p4y, iter = 1000, subseq=F, plot=FALSE)
t5 = turnover_w(data = p5y, iter = 1000, subseq=F, plot=FALSE)
t6 = turnover_w(data = p6y, iter = 1000, subseq=F, plot=FALSE)
t7 = turnover_w(data = p7y, iter = 1000, subseq=F, plot=FALSE)
t8 = turnover_w(data = p8y, iter = 1000, subseq=F, plot=FALSE)
all = rbind(t1, t2, t3, t4, t5, t6, t7, t8)
all = cbind(c(1, 2, 3, 4, 5, 6, 7, 8), all)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.34,0.43), xlim=c(1,8), cex.axis=0.8)
axis(1, at=c(1, 2, 3, 4, 5, 6, 7, 8),las=1, cex.axis=0.7)
mtext(side = 1, "Length of periods (years)", line = 2, font = 1)
axis(3, at=c(1, 2, 3, 4, 5, 6, 7, 8),las=1, labels=c(22, 11, 7, 6, 5, 4, 3, 3), cex.axis=0.7)
mtext(side = 3, "Number of periods", line = 2, font = 1)
# Print final results
all
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.30,0.7), xlim=c(1,8), cex.axis=0.8)
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.5,0.6), xlim=c(1,8), cex.axis=0.8)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.56,0.61), xlim=c(1,8), cex.axis=0.8)
par(mar=c(4,5,4,1))
# Plot the final results. Whisker represent 95%CI generated by the null model. X-axis represent the number of periods and their respective lengths
errbar(x=c(1, 2, 3, 4, 5, 6, 7, 8), y=all[,2], all[,4], all[,5], ylab="Turnover (Averaged Whittaker Dissimilarity)",
pch=1, cap=0.02, xaxt='n', xlab="", las=1, cex=1.0, ylim=c(0.565,0.61), xlim=c(1,8), cex.axis=0.8)
gc()
# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
# Read file in to retain ILV
sample_data <- read.csv("sample_data.csv")
list_years <- readRDS("list_years.RData")
# Extract specific columns from each data frame in list_years
aux <- lapply(list_years, function(df) {
data.frame(
Code = df$Code,
Behaviors = df$Behaviors,
HumanInteraction = df$HumanInteraction,
ConfHI = df$ConfHI
)
})
# Add the 'Foraging' variable to each data frame in the 'aux' list
aux <- lapply(aux, function(df) {
df$Foraging <- "Other"
df$Foraging[grepl(pattern = 'Feed', x = df$Behaviors, ignore.case = FALSE)] <- "Feed"
df
})
# Categorize ID to Foraging
IDbehav <- lapply(aux, function(df) {
df <- table(df$Code, df$Foraging)
df <- as.data.frame(df, stringsAsFactors = FALSE)
df <- df[, c(1, 3)]
colnames(df) <- c("Code", "Forg_Freq")
df <- aggregate(. ~ Code, data = df, sum)
df
})
# HI behaviors should be partitioned into 3 different types
#' B = Begging (direct provisioning): F, G, H
#' P = patrolling/scavenging (indirect): A, B, C
#' D = foraging around fixed gear (humans not present):D, E, P
# Fix the code using ifelse statements
for (i in seq_along(aux)) {
aux[[i]]$ConfHI <- ifelse(aux[[i]]$ConfHI %in% c("F", "G", "H"), "B",
ifelse(aux[[1]]$ConfHI %in% c("A", "B", "C"), "S",
ifelse(aux[[i]]$ConfHI %in% c("D", "E", "P"), "D", "0")))
}
# Categorize ConfHI to IDs
rawHI <- lapply(aux, function(df) {
df <- as.matrix(table(df$Code, df$ConfHI))
df <- as.data.frame(df, stringsAsFactors = FALSE)
colnames(df) <- c("Code", "ConfHI", "Freq")
df
})
# Create a different frequency count for each HI behavior
get_IDHI <- function(confHI) {
lapply(seq_along(IDbehav), function(i) {
df <- IDbehav[[i]]
df$HI <- rawHI[[i]]$Freq[rawHI[[i]]$ConfHI == confHI & rawHI[[i]]$ConfHI != "0"]
colnames(df) <- c("Code", "Foraging", "HI")
df
})
}
IDbehav_Beg <- get_IDHI("B")
IDbehav_Pat <- get_IDHI("S")
IDbehav_Dep <- get_IDHI("D")
saveRDS(IDbehav_Beg, file = "../data/IDbehav_Beg.RData")
saveRDS(IDbehav_Pat, file = "../data/IDbehav_Pat.RData")
saveRDS(IDbehav_Dep, file = "../data/IDbehav_Dep.RData")
# Get unique behavior assignments
status <- function(IDbehav, HI, NonHI){
lapply(seq_along(IDbehav), function(i) {
IDbehav[[i]]$Stat <- ifelse(IDbehav[[i]]$HI > 0, HI, NonHI)
df <- IDbehav[[i]][, c('Code', 'Stat')]
df
})
}
## Match each individual with it's behavior
Beg <- status(IDbehav_Beg, "B", "NB")
Pat <- status(IDbehav_Pat, "P", "NP")
Dep <- status(IDbehav_Dep, "D", "ND")
# Read in social association matrix and data
nxn <- readRDS("nxn.RData")
View(Beg)
lapply(replace_ID_with_HI(nxn, Beg))
lapply(nxn, replace_ID_with_HI(nxn, Beg))
lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Beg))
# Replace individuals in the matrix with their assigned behavior
replace_ID_with_HI <- function(sri_matrix, ID_HI_df) {
# Create vector that matches IDs to their stat
id_to_stat <- setNames(ID_HI_df$Stat, ID_HI_df$Code)
# Replace each ID with stat in row and column names
row_names <- id_to_stat[rownames(sri_matrix)]
col_names <- id_to_stat[colnames(sri_matrix)]
# Create the replaced matrix
replaced_matrix <- sri_matrix
# Assign row and column names with behavioral states
dimnames(replaced_matrix) <- list(row_names, col_names)
return(replaced_matrix)
}
lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Beg))
# Make a replaced nxn for each behavior
Beg_nxn <- lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Beg))
Pat_nxn <- lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Pat))
Dep_nxn <- lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Dep))
### Beg---------------------------------------------
## Step 2: Extract the combinations
NB_NB <- replaced_nxn[is_NB, is_NB]
for (i in seq_along(Beg_nxn)) {
is_NB <- rownames(Beg_nxn[[i]]) == "NB"
is_B <- rownames(Beg_nxn[[i]]) == "B"
}
is_NB <- rownames(Beg_nxn[[1]]) == "NB"
View(Beg_nxn)
Beg_nxn[[1]]
View(Beg)
# Make a replaced nxn for each behavior
Beg_nxn <- lapply(nxn, function(matrix) replace_ID_with_HI(matrix, Beg))
View(Beg_nxn)
replace_ID_with_HI(nxn[[1]], Beg[[1]])
lapply(seq_along(nxn), function(i) {
replace_ID_with_HI(nxn[[i]], Beg[[i]])
})
# Make a replaced nxn for each behavior
Beg_nxn <- lapply(seq_along(nxn), function(i) {
replace_ID_with_HI(nxn[[i]], Beg[[i]])
})
View(Beg_nxn)
Beg_nxn[[1]]
Beg_nxn[[2]]
Pat_nxn <- lapply(seq_along(nxn), function(i) {
replace_ID_with_HI(nxn[[i]], Pat[[i]])
})
Dep_nxn <- lapply(seq_along(nxn), function(i) {
replace_ID_with_HI(nxn[[i]], Dep[[i]])
})
for (i in seq_along(Beg_nxn)) {
is_NB <- rownames(Beg_nxn[[i]]) == "NB"
is_B <- rownames(Beg_nxn[[i]]) == "B"
}
for (i in seq_along(Pat_nxn)) {
is_NS <- rownames(Pat_nxn[[i]]) == "NS"
is_S <- rownames(Pat_nxn[[i]]) == "S"
}
for (i in seq_along(Dep_nxn)) {
is_ND <- rownames(Dep_nxn[[i]]) == "ND"
is_D <- rownames(Dep_nxn[[i]]) == "D"
}
## Step 2: Extract the combinations
NB_NB <- NB_B <- B_NB <- B_B <- list()
for (i in seq_along(Beg_nxn)) {
NB_NB[[i]] <- Beg_nxn[[i]][is_NB, is_NB]
NB_B[[i]] <- Beg_nxn[[i]][is_NB, is_B]
B_NB[[i]] <- Beg_nxn[[i]][is_B, is_NB]
B_B[[i]] <- Beg_nxn[[i]][is_B, is_B]
}
### Function to extract combinations
extract_combs <- function(HI_nxn, is_row, is_col) {
combs <- lapply(HI_nxn, function(matrix_entry) matrix_entry[is_row, is_col])
names(combs) <- names(HI_nxn)
return(combs)
}
#### Apply for each stat comb
NB_NB <- extract_combs(Beg_nxn, is_NB, is_NB)
Dep_nxn[[1]][is_ND, is_ND]
is_NB <- is_B <- list()
for (i in seq_along(Beg_nxn)) {
is_NB[[i]] <- rownames(Beg_nxn[[i]]) == "NB"
is_B[[i]] <- rownames(Beg_nxn[[i]]) == "B"
}
is_NS <- is_S <- list()
for (i in seq_along(Pat_nxn)) {
is_NS[[i]] <- rownames(Pat_nxn[[i]]) == "NS"
is_S[[i]] <- rownames(Pat_nxn[[i]]) == "S"
}
is_ND <- is_D <- list()
for (i in seq_along(Dep_nxn)) {
is_ND[[i]] <- rownames(Dep_nxn[[i]]) == "ND"
is_D[[i]] <- rownames(Dep_nxn[[i]]) == "D"
}
### Function to extract combinations
extract_combs <- function(HI_nxn, is_row, is_col) {
combs <- lapply(seq_along(HI_nxn), function(i) {
HI_nxn[[i]][is_row[[i]], is_col[[i]]]
})
return(combs)
}
#### Apply for each stat comb
NB_NB <- extract_combs(Beg_nxn, is_NB, is_NB)
View(NB_NB)
NB_B <- extract_combs(Beg_nxn, is_NB, is_B)
B_NB <- extract_combs(Beg_nxn, is_B, is_NB)
B_B <- extract_combs(Beg_nxn, is_B, is_B)
NS_NS <- extract_combs(Pat_nxn, is_NS, is_NS)
NS_S <- extract_combs(Pat_nxn, is_NS, is_S)
S_NS <- extract_combs(Pat_nxn, is_S, is_NS)
S_S <- extract_combs(Pat_nxn, is_S, is_S)
ND_ND <- extract_combs(Dep_nxn, is_ND, is_ND)
ND_D <- extract_combs(Dep_nxn, is_ND, is_D)
D_ND <- extract_combs(Dep_nxn, is_D, is_ND)
D_D <- extract_combs(Dep_nxn, is_D, is_D)
### Function to calculate avg
avg_comb <- function(a, b, c, d) {
avg_a <- lapply(seq_along(a), function(i) {
mean(a[[i]][lower.tri(a[[i]])])
})
avg_b <- lapply(seq_along(b), function(i) {
mean(b[[i]][lower.tri(b[[i]])])
})
avg_c <- lapply(seq_along(c), function(i) {
mean(c[[i]][lower.tri(c[[i]])])
})
avg_d <- lapply(seq_along(d), function(i) {
mean(d[[i]][lower.tri(d[[i]])])
})
avg_vect <- rbind(avg_a, avg_b, avg_c, avg_d)
return(avg_vect)
}
### Function to calculate avg
avg_comb <- function(a, b, c, d) {
avg_a <- lapply(seq_along(a), function(i) {
mean(a[[i]][lower.tri(a[[i]])])
})
avg_b <- lapply(seq_along(b), function(i) {
mean(b[[i]][lower.tri(b[[i]])])
})
avg_c <- lapply(seq_along(c), function(i) {
mean(c[[i]][lower.tri(c[[i]])])
})
avg_d <- lapply(seq_along(d), function(i) {
mean(d[[i]][lower.tri(d[[i]])])
})
avg_list <- c(avg_a, avg_b, avg_c, avg_d)
return(avg_list)
}
avg_Beg <- avg_comb(NB_NB, NB_B, B_NB, B_B)
View(avg_Beg)
### Function to calculate avg
avg_comb <- function(a, b, c, d) {
avg_a <- lapply(seq_along(a), function(i) {
mean(a[[i]][lower.tri(a[[i]])])
})
avg_b <- lapply(seq_along(b), function(i) {
mean(b[[i]][lower.tri(b[[i]])])
})
avg_c <- lapply(seq_along(c), function(i) {
mean(c[[i]][lower.tri(c[[i]])])
})
avg_d <- lapply(seq_along(d), function(i) {
mean(d[[i]][lower.tri(d[[i]])])
})
avg_list <- list(avg_a, avg_b, avg_c, avg_d)
return(avg_list)
}
avg_Beg <- avg_comb(NB_NB, NB_B, B_NB, B_B)
View(avg_Beg)
### Function to calculate avg
avg_comb <- function(a, b, c, d) {
avg_a <- lapply(seq_along(a), function(i) {
mean(a[[i]][lower.tri(a[[i]])])
})
avg_b <- lapply(seq_along(b), function(i) {
mean(b[[i]][lower.tri(b[[i]])])
})
avg_c <- lapply(seq_along(c), function(i) {
mean(c[[i]][lower.tri(c[[i]])])
})
avg_d <- lapply(seq_along(d), function(i) {
mean(d[[i]][lower.tri(d[[i]])])
})
avg_df <- data.frame(
Avg_A = unlist(avg_a),
Avg_B = unlist(avg_b),
Avg_C = unlist(avg_c),
Avg_D = unlist(avg_d)
)
return(avg_df)
}
avg_Beg <- avg_comb(NB_NB, NB_B, B_NB, B_B)
View(avg_Beg)
colnames(avg_Beg) <- c("NB_NB", "NB_B", "B_NB", "B_B")
View(avg_Beg)
avg_Pat <- avg_comb(NS_NS, NS_S, S_NS, S_S)
colnames(avg_Beg) <- c("NS_NS", "NS_S", "S_NS", "S_S")
avg_Dep <- avg_comb(ND_ND, ND_D, D_ND, D_D)
colnames(avg_Beg) <- c("ND_ND", "ND_D", "D_ND", "D_D")
View(avg_Pat)
View(avg_Dep)
