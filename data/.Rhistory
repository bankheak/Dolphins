x
x <- 4
x <- 6
x
source("C:/Users/bankh/Box/OSU/FW320_Teaching Material/test_code.R", echo=TRUE)
source("C:/Users/bankh/Box/OSU/FW320_Teaching Material/test_code.R", echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
#4.
(1 + 2) * (3 *5)
(1 + 2) * 3 * 5
#5.
log(x)
#6.
y <- c(2, 3, 5, 7)
class(y)
length(y)
#7.
?seq
seq(from = 1, to = 23, by = 0.5)
#8.
matrix(c(1:9), nrow = 3, ncol = 3)
#9.
my_list <- list(5, "hello", TRUE, 1+4i)
length(my_list)
#10.
df <- data.frame(id = letters[1:10], x = 1:10, y = 11:20)
tail(df)
tail(df)
head(df)
x <- c(2, 4, 6, 8, 10)
y <- c(10, 20, 30, 40, 50)
plot(x, y)
#14.
plot(temp, fishA, pch = 17, xlab = "temperature (degrees C)", ylab = "opercular beats (bpm)")
#14.
temp <- c(5, 8, 12, 16, 20, 23)
fishA <- c(36, 42, 59, 73, 88, 96)
fishB <- c(40, 49, 61, 71, 82, 90)
plot(temp, fishA, pch = 17, xlab = "temperature (degrees C)", ylab = "opercular beats (bpm)")
points(temp, fishB, pch = 19, col = "dimgray")
plot(temp, fishA, pch = 17, xlab = "temperature (degrees C)", ylab = "opercular beats (bpm)")
points(temp, fishB, pch = 19, col = "dimgray")
?points
#15.
x = c(1,4,5)
y = c(2,8,9)
cor(x, y)
plot(x, y, pch = 17, type = "l", xlab = "X", ylab = "Y")
x = c(1,4,5)
y = c(2,0,-5)
cor(x, y)
plot(x, y, pch = 17, type = "l", xlab = "X", ylab = "Y")
setwd("C:/Users/bankh/Box/OSU/FW320_Teaching Material")
#this line imports your data into a dataframe that we get to name. Make sure the csv file is in the same folder as this Rmarkdown file.  Note that "<-" and "=" both work for assigning something to an object.
count_data <- read.csv("salamander_counts.csv")
count_data #Let's output the data so you can see it
#note column names have been added already in the csv. Note that column names can't contain spaces.
#use sum() to find the total number of salamanders counted and and length() to find the number of
#observations, which we can compare with the mean() function. Remember to use the $ to specify which column in the dataframe to use
Mean_density_low <- sum(count_data$lower_elev_site)/length(count_data$lower_elev_site)
Mean_density_low2 <- mean(count_data$lower_elev_site)
#Compare the two summary statistics - type the object name to ask R to return its value
Mean_density_low
Mean_density_low2
#For the manual expression, we can take advantage of the way R handles vectors
#The object count_data$lower_elev_site is a vector (a list of numbers):
count_data$lower_elev_site
#we use the object storing the mean (Mean_density_low) to find the raw
#difference from the mean of each observation:
count_data$lower_elev_site -  Mean_density_low
#We can then square every one of these values:
(count_data$lower_elev_site -  Mean_density_low)^2
#Now we van do this in one expression: we create an object called Variance_low, find
#the difference from the mean of every data point, square them, add them up, and divide by the total number of counts (the length of our dataset) - 1. This is the formula for the variance.
Variance_low <- sum((count_data$lower_elev_site -
Mean_density_low)^2)/(length(count_data$lower_elev_site) - 1)
#note the multiple sets of parentheses! These are necessary to close functions and to define the order of operations (PEMDAS)
#OR we can do this the easy way, using the internal function var()
Variance_low2 <- var(count_data$lower_elev_site)
#Compare the outputs:
Variance_low
Variance_low2
#plot histograms (frequency plots) of our data for the low evelation site
#HINT: remember to use the $ to specify which column in the dataframe to use in hist()
#We can also set the number of breaks (bins) to be equal in both plots
#We use some optional arguments of hist() to label the x-axis, and title each plot.
#now we use the function hist() with three arguments - xlab, main, and breaks to label the x axis, title, and define how many bins we want in our histogram.:
hist(count_data$lower_elev_site, xlab = "Counts", main = "Low Elevation Site",  breaks = 10)
#we will use the function mtext() to add the mean and standard deviation (SD) to the histogram for the low elevation site. The SD is the square root of the variance, so we can wrap that into our line of code. We also use the function round() because R will return an overly precise version of the SD. Do you think maybe R has a function to find the standard deviation? Of course it does. Instead of using sqrt(Variance_low), you can see what happens when using the sd() function.
mtext(paste("Mean is", Mean_density_low, "salamanders per square meter"),side = 3, line = 0.5, cex=0.75)
mtext(paste("SD is", round(sqrt(Variance_low), 2), "salamanders per square meter"),side = 3, line = -0.5, cex=0.75)
#Look at the help documentation for mtext()! You can use ?mtext or help(mtext). What does the "side" argument do? Look at the help documentation for paste(). What does this do? We are intentionally not telling you exactly how to use mtext because the most important thing to learn when coding is how to find answers to questions. That is how your skillset will grow.
#NOTE: We can plot two histograms (for each site) with the plot-partitioning
#function par(). The par function has tricky syntax, but the mfrow option takes a vector with the number of rows and columns to plot figure panels in. We can create 1 row and 2 column panels with:
par(mfrow=c(1, 2))
hist(count_data$lower_elev_site, xlab = "Counts", main = "Low Elevation Site",  breaks = 10)
hist(count_data$lower_elev_site, xlab = "Counts", main = "High Elevation Site",  breaks = 10)
Mean_density_low*10000*2 #units are now number of salamanders
estimate_low <- Mean_density_low*10000*2
#units are now number of salamanders
Mean_density_high <- sum(count_data$high_elev_site)/length(count_data$high_elev_site)
estimate_high <- Mean_density_high*10000*3.5
View(count_data)
knitr::opts_chunk$set(echo = TRUE)
# N/(2*L*ESW)
16/(2 * 500 * 10)
# N/(2*L*ESW)
16/(2 * 500 * 10 * 4)
knitr::opts_chunk$set(echo = TRUE)
data_1 <- read.csv("Lab3-4_dataset1.csv")
plot(data_1$years, data_1$Population, xlab="Years", ylab="Population Size", pch = 20)
mu <- mean(r)
QET <- 2 #Set the QET, I'll choose a low QET of 2 for this example.
N.pops<-100 #Number of populations to simulate. It's smart to make this a variable so that these parameters can be easily changed in just one place to modify the model.
N.years<-50 #It's smart to make this a variable.
N.projected<-matrix(0,nrow=N.years,ncol=N.pops) #make a matrix full of zeros where there is a column for each population to be simulated and a row for each year of the simulation
N.projected[1,]<-dataset1$Population[30] #Set the initial size for all populations to begin the projection with last observed population datapoint, which in this case is population at the 30th year. The notation for N.projected[1,] means 1st row (year 1) and all columns (populations)
dataset1 <- read.csv("Lab3-4_dataset1.csv")
plot(dataset1$years, dataset1$Population, xlab="Years", ylab="Population Size", pch = 20)
N.projected[1,]<-dataset1$Population[30] #Set the initial size for all populations to begin the projection with last observed population datapoint, which in this case is population at the 30th year. The notation for N.projected[1,] means 1st row (year 1) and all columns (populations)
# Now we are going to use a loop to iterate over each year within each population. This is called a "for loop", and it's very common to use a counter that takes a new value each time through the loop. Here "pop" will be a counter that takes all integer values from 1 to N.pops, and "yr" will be a counter that takes all values from year 1 to year N.year-1 (because we calculate the next year's population using data from the current year). Each year we will generate a random r from a Normal distribution (bell curve) with mean mu and standard deviation sigma in order to generate a random lambda by exponentiating r using the rnorm() function. Use ?rnorm in the Console to read the documentation. rnorm() will take parameters for the number of random normals to generate (for us it's just 1 random draw), as well as mu and sigma. Note that this is computationally slower than another method, which would be to only iterate by year and generate all the 100 random normal variables at once rather than one at a time. This can be accomplished because the syntax of rnorm() begins with the number of random draws, so we'd select 100 random draws. We're using two for loops, which is referred to as a nested for loop, so that you can learn how this works.
#
for(pop in 1:N.pops){ #outer loop begins
for(yr in 1:(N.years-1)){ #inner loop begins, note the parentheses around (N.years-1) so that we don't use an subscript out of bounds. The last value for yr will be N.years - 1
random_r<-rnorm(1,mu,sigma) #generate 1 random value from a Normal distribution with mean mu and standard deviation sigma. Note that these variables will have to be named whatever you named them when you calculated them above.
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r) #For one population at a time, indexed by pop, we fill in the projected population size for all years (one at a time with inner loop)
}  #inner loop ends
}#outer loop ends
mu <- mean(r)
Pop_t <- dataset1$Population[1:29]
Pop_t1 <- dataset1$Population[2:30]
lambda <- Pop_t1/Pop_t
r <- log(lambda)
hist(r)
mu <- mean(r)
sigma <- sd(r)
# Now we are going to use a loop to iterate over each year within each population. This is called a "for loop", and it's very common to use a counter that takes a new value each time through the loop. Here "pop" will be a counter that takes all integer values from 1 to N.pops, and "yr" will be a counter that takes all values from year 1 to year N.year-1 (because we calculate the next year's population using data from the current year). Each year we will generate a random r from a Normal distribution (bell curve) with mean mu and standard deviation sigma in order to generate a random lambda by exponentiating r using the rnorm() function. Use ?rnorm in the Console to read the documentation. rnorm() will take parameters for the number of random normals to generate (for us it's just 1 random draw), as well as mu and sigma. Note that this is computationally slower than another method, which would be to only iterate by year and generate all the 100 random normal variables at once rather than one at a time. This can be accomplished because the syntax of rnorm() begins with the number of random draws, so we'd select 100 random draws. We're using two for loops, which is referred to as a nested for loop, so that you can learn how this works.
#
for(pop in 1:N.pops){ #outer loop begins
for(yr in 1:(N.years-1)){ #inner loop begins, note the parentheses around (N.years-1) so that we don't use an subscript out of bounds. The last value for yr will be N.years - 1
random_r<-rnorm(1,mu,sigma) #generate 1 random value from a Normal distribution with mean mu and standard deviation sigma. Note that these variables will have to be named whatever you named them when you calculated them above.
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r) #For one population at a time, indexed by pop, we fill in the projected population size for all years (one at a time with inner loop)
}  #inner loop ends
}#outer loop ends
N.projected
#Let's look at all our trajectories with the matplot() function, which plots all columns of a matrix.
matplot(N.projected, type = "l", xlab = "Year", ylab = "Population", col = "gray")
matplot(N.projected, type = "l", xlab = "Year", ylab = "Population", col = "gray")
#Make a horizontal line at the value of the QET using the abline function. lwd is for line width. h=QET says to make a horizontal line where the y axis equals the QET we set above
abline(h=QET,col="red",lwd=2)
matplot(N.projected, type = "l", xlab = "Year", ylab = "Population", col = "gray")
abline(h=QET,col="red",lwd=2)
lines(rowMeans(N.projected))
#Now ask what proportion of population trajectories fall below our QET at least once by comparing the minimum population for each trajectory to the QET.
#we will use the apply function, apply(), which is a fancy way to apply a function to either every row or column. In this case we will use it to find the minimum of every column (simulated population) with the notation apply(data to work on, 1 for row or 2 for column, and the function to apply, which is the function "min" in this case). The apply function will output the minimum value for each trajectory.
apply(N.projected,2,min)
#Now we can ask if these fall below the QET and get TRUE or FALSE out for each column
apply(N.projected,2,min)<QET
mean(apply(N.projected,2,min)<QET) #This is a slick way to find the proportion of populations that fall below the QET at some point in the projection.
#What proportion of populations are below QET each year? We can use the rowMeans function to ask what proportion of populations are below the QET each year. N.projected<QET turns every value in N.projected into a true or false, and then the mean of the resulting 1s and 0s in each row gives us the proportion below QET in that year.
rowMeans(N.projected<QET)
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
QET <- 2 # Because the population seemed to recover from going below 2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
QET <- 10 # Because the population seemed to recover from going below 2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
QET <- 10 *2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
10/2
10*2
# Multiplied by 2
QET <- 10*2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
# Divided by 2
QET <- 10/2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
dataset2 <- read.csv("Lab3-4_dataset2.csv")
plot(dataset2$years, dataset2$Population)
dataset2 <- read.csv("Lab3-4_dataset2.csv")
plot(dataset2$years, dataset2$Population)
lambda <- dataset2$Population[2:nrow(dataset2)]/dataset2$Population[1:(nrow(dataset2)-1)]
r <- log(lambda)
hist(r)
mu <- mean(r)
sigma <- sd(r)
QET <- 2
N.pops<-100
N.years<-100
N.projected<-matrix(0,nrow=N.years,ncol=N.pops)
N.projected[1,]<-dataset1$Population[30]
for(pop in 1:N.pops){
for(yr in 1:(N.years-1)){
random_r<-rnorm(1,mu,sigma)
N.projected[yr+1,pop]<-N.projected[yr,pop]*exp(random_r)
}
}
#Let's look at all our trajectories
mean(apply(N.projected,2,min)<QET)
#What proportion of populations are below QET each year?
plot(rowMeans(N.projected<QET)*100,ylab="% Populations below QET", xlab ="Year",type="l",lwd=2)
abline(h=5, col="red")
setwd("C:/Users/bankh/My_Repos/Dolphins/code")
nxn <- readRDS("nxn.RData") # association matrix of list_years
setwd("C:/Users/bankh/My_Repos/Dolphins/code")
# Set working directory here
setwd("../data")
# Read in full datasheet and list (after wrangling steps)
list_years <- readRDS("list_years.RData") # (1995-2000)/(2001-2006)/(2007-2012)
nxn <- readRDS("nxn.RData") # association matrix of list_years
## Create social network
ig_func <- function(nxn) {
ig <- lapply(nxn, function (df) {
graph_from_adjacency_matrix(
df,
mode = "undirected",
weighted = TRUE,
diag = FALSE)})
return(ig)}
ig <- ig_func(nxn)
library(tnet) # For weights
library(igraph) # Measure centrality here
library(ggraph)
library(grid)
library(assortnet) # associative indices
library(ggplot2) # Visualization
library(abind) # array
library(MCMCglmm) # MCMC models
library(coda)
library(bayesplot) # plot parameters
library(doParallel)
source("../code/functions.R") # Matrix_to_edge_list
## Create social network
ig_func <- function(nxn) {
ig <- lapply(nxn, function (df) {
graph_from_adjacency_matrix(
df,
mode = "undirected",
weighted = TRUE,
diag = FALSE)})
return(ig)}
ig <- ig_func(nxn)
# Set the node names based on row names
row_name_assign <- function(nxn, ig) {
row_names <- lapply(nxn, function (df) {rownames(df)})
for (i in seq_along(ig)) {
V(ig[[i]])$name <- row_names[[i]]
}
}
row_name_assign(nxn, ig)
# Only show IDs of HI dolphins
row_name_HI_func <- function(list_years) {
HI_data <-  diff_raw(subset_HI(list_years))
row_names_HI <- lapply(HI_data, function (df) {
as.vector(df$Code[(df$DiffHI == "BG" | df$DiffHI == "SD" |
df$DiffHI == "FG") & df$Freq > 0])})
return(row_names_HI)
}
row_names_HI <- row_name_HI_func(list_years)
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4, # edge thickness
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10), # Changes node size based on an individuals strength (centrality)
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
}
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow = c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
# Set up a new plot region
plot.new()
# Set up the layout
layout(1, widths = 1, heights = 1)
# Add the plot with a box around it
box()
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4,
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10),
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
}
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
# Set up the layout
layout(1, widths = 1, heights = 1)
# Add the plot with a box around it
box()
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4, # edge thickness
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10), # Changes node size based on an individuals strength (centrality)
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
}
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
# Set up a new plot region
plot.new()
# Set up the layout
layout(1, widths = 1, heights = 1)
# Add the plot with a box around it
box()
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4, # edge thickness
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10), # Changes node size based on an individuals strength (centrality)
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
}
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
# Add the plot with a box around it
box()
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4, # edge thickness
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10), # Changes node size based on an individuals strength (centrality)
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
}
# Plot network
# Set up the plotting area with 1 row and 2 columns for side-by-side plots
par(mfrow=c(1, 3), mar = c(0.5, 0.5, 0.5, 0.5))
main_labels <- c("Before Network", "During Network", "After Network")
# Loop through the list of graphs and plot them side by side
for (i in 1:length(ig)) {
plot(ig[[i]],
layout = layout_with_fr(ig[[i]]),
edge.width = E(ig[[i]])$weight * 4, # edge thickness
vertex.size = sqrt(igraph::strength(ig[[i]], vids = V(ig[[i]]), mode = c("all"), loops = TRUE) * 10), # Changes node size based on an individuals strength (centrality)
vertex.frame.color = NA,
vertex.label.family = "Helvetica",
vertex.label = ifelse(V(ig[[i]])$name %in% row_names_HI[[i]], V(ig[[i]])$name, NA),
vertex.label.color = "black",
vertex.label.cex = 0.8,
vertex.label.dist = 2,
vertex.frame.width = 0.01)
# Add the main label above the plot
title(main = main_labels[i], line = -1)
# Add the plot with a box around it
box()
}
