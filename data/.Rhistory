# Set working directory here
setwd("C:/Users/bankh/My_Repos/Dolphins/data")
setwd("C:/Users/bankh/My_Repos/Dolphins/code")
# Set working directory here
setwd("../data")
library(abind) # array
library(MCMCglmm) # MCMC models
library(coda)
library(bayesplot) # plot parameters
dist_BG <- readRDS("dist_BG.RData") # BG Sim Matrix
dist_FG <- readRDS("dist_FG.RData") # FG Sim Matrix
dist_SD <- readRDS("dist_SD.RData") # SD Sim Matrix
ILV_mat <-readRDS("ILV_mat.RData") # Age and Sex Matrices
kov <- readRDS("kov.RDS")  # Home range overlap
nxn <- readRDS("nxn.RData") # Association Matrix
# Prepare random effect for MCMC
num_nodes <- lapply(nxn, function(df) dim(df)[1])
node_names <- lapply(nxn, function(df) colnames(df))
# Separate IDs into i and j
node_ids_i <- lapply(num_nodes, function(df) matrix(rep(1:df, each = df), nrow = df, ncol = df))
node_ids_j <- lapply(node_ids_i, function(df) t(df))
# Format data
upper_tri <- lapply(nxn, function(df) upper.tri(df, diag = TRUE))
edge_nxn <- abind(lapply(nxn, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
HAB_data <- cbind(c(edge_nxn[,1], edge_nxn[,2]), c(rep(0, nrow(edge_nxn)), rep(1, nrow(edge_nxn)))) # Two
BG <- abind(lapply(dist_BG, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
FG <- abind(lapply(dist_FG, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
SD <- abind(lapply(dist_SD, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
#SE <- abind(lapply(SE_list, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
one <- lapply(seq_along(node_ids_i), function(i) factor(as.vector(node_names[[i]][node_ids_i[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
two <- lapply(seq_along(node_ids_j), function(i) factor(as.vector(node_names[[i]][node_ids_j[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
# Put data into a dataframe
period = 2
df_list = data.frame(edge_weight = HAB_data[, 1],
HAB = HAB_data[, 2],
HRO = unlist(lapply(kov, function (df) df[upper.tri(df, diag = TRUE)])),
sex_similarity = rep(ILV_mat[[1]][upper.tri(ILV_mat[[1]], diag = TRUE)], period),
age_difference = rep(ILV_mat[[2]][upper.tri(ILV_mat[[2]], diag = TRUE)], period),
#GR = gr_list,
#HI_differences = c(HI[,c(1:period)]),
BG_differences = c(BG[,c(1:period)]),
FG_differences = c(FG[,c(1:period)]),
SD_differences = c(SD[,c(1:period)]),
#Obs.Err = c(SE[,1], SE[,2]),
node_id_1 = unlist(one),
node_id_2 = unlist(two))
## HI Behavior Separated Two Year Period ##
fit_mcmc.2 <- MCMCglmm(edge_weight ~ BG_differences * HAB + FG_differences * HAB +
SD_differences * HAB + HRO + age_difference + sex_similarity,
random=~mm(node_id_1 + node_id_2), data = df_list, nitt = 15000)
summary(fit_mcmc.2)
# Check for model convergence
plot(fit_mcmc.2$Sol)
plot(fit_mcmc.2$VCV)
# Extract Posteriors
posterior <- fit_mcmc.2$Sol
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", #"HI_differences", "HI_differences:HAB",
"HAB", "BG_difference:HAB", "HAB:FG_differences", "HAB:SD_differences",
"age_difference", "sex_similarity", "HRO"))
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", #"HI_differences", "HI_differences:HAB",
"HAB", "HAB:BG_difference", "HAB:FG_differences", "HAB:SD_differences",
"age_difference", "sex_similarity", "HRO"))
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", #"HI_differences", "HI_differences:HAB",
"HAB", "BG_differences:HAB", "HAB:FG_differences", "HAB:SD_differences",
"age_difference", "sex_similarity", "HRO"))
# Read in full datasheet and list (after wrangling steps)
orig_data <- read.csv("orig_data.csv") # original data
# Visualize data: HAB v HI
HAB_HI_data <- orig_data[, c("Year", "ConfHI")]
HAB_HI_data$ConfHI <- ifelse(HAB_HI_data$ConfHI != "0", 1, 0)
HAB_HI_data <- aggregate(ConfHI ~ Year, data = HAB_HI_data, FUN = function(x) sum(x == 1))
HAB_HI_data$HAB <- c(rep(0, 4), 5, 0, 12, 8, 18, 5, 38, 19, 2, rep(0, 5))
# Create a scatter plot with a trend line
ggplot() +
geom_bar(aes(x = Year, y = ConfHI), data = HAB_HI_data, fill = "blue", alpha = 0.5) +
geom_bar(aes(x = Year, y = HAB), data = HAB_HI_data, fill = "orange", alpha = 0.5) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "Separated Bar Plots", x = "Year")
library(ggplot2) # Visualization
# Create a scatter plot with a trend line
ggplot() +
geom_bar(aes(x = Year, y = ConfHI), data = HAB_HI_data, fill = "blue", alpha = 0.5) +
geom_bar(aes(x = Year, y = HAB), data = HAB_HI_data, fill = "orange", alpha = 0.5) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "Separated Bar Plots", x = "Year")
# Create a scatter plot with a trend line
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI), fill = "blue", alpha = 0.5, position = position_dodge(width = 0.8)) +
geom_bar(aes(y = HAB), fill = "orange", alpha = 0.5, position = position_dodge(width = 0.8)) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "Separated Bar Plots", x = "Year")
ggplot(HAB_HI_data, aes(Year, ConfHI)) +
geom_point() +
scale_y_continuous(
"HAB",
sec.axis = sec_axis(~ . * 1.20, name = "ConfHI")
)
ggplot(HAB_HI_data, aes(Year, ConfHI)) +
geom_bar() +
scale_y_continuous(
"HAB",
sec.axis = sec_axis(~ . * 1.20, name = "ConfHI")
)
ggplot(HAB_HI_data, aes(x=Year, y = ConfHI)) +
geom_col(position="dodge") +
scale_y_continuous(sec.axis = sec_axis(~ . * 10, name = "HAB"))+
labs(y="ConfHI")
# Create a scatter plot with a trend line
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI), stat = "identity", fill = "blue", alpha = 0.5, position = position_dodge(width = 0.8)) +
geom_bar(aes(y = HAB), stat = "identity", fill = "orange", alpha = 0.5, position = position_dodge(width = 0.8)) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "Separated Bar Plots", x = "Year")
# Create a scatter plot with a trend line
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI), stat = "identity", fill = "blue", alpha = 0.5) +
labs(title = "Bar Plot for ConfHI", x = "Year", y = "ConfHI") +
facet_grid(vars(.), scales = "free_y") +
geom_bar(aes(y = HAB), stat = "identity", fill = "orange", alpha = 0.5) +
labs(title = "Bar Plot for HAB", y = "HAB") +
theme(strip.background = element_blank(), strip.text = element_blank())
View(HAB_HI_data)
# Create a scatter plot with a trend line
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI), stat = "identity", fill = "blue", alpha = 0.5, position = position_dodge(width = 0.8)) +
geom_bar(aes(y = HAB), stat = "identity", fill = "orange", alpha = 0.5, position = position_dodge(width = 0.8)) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "Separated Bar Plots", x = "Year")
# Create a scatter plot with a trend line
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI), stat = "identity", fill = "blue", alpha = 0.5, position = position_dodge(width = 0.8)) +
geom_bar(aes(y = HAB), stat = "identity", fill = "orange", alpha = 0.5, position = position_dodge(width = 0.8)) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "HAB and HI over Years", x = "Year")
# Create a barplot
ggplot(aes(x = Year), data = HAB_HI_data) +
geom_bar(aes(y = ConfHI, fill = "ConfHI"), stat = "identity", alpha = 0.5, position = position_dodge(width = 0.8)) +
geom_bar(aes(y = HAB, fill = "HAB"), stat = "identity", alpha = 0.5, position = position_dodge(width = 0.8)) +
scale_y_continuous(name = "ConfHI", sec.axis = sec_axis(~., name = "HAB")) +
labs(title = "HAB and HI over Years", x = "Year") +
scale_fill_manual(values = c("ConfHI" = "blue", "HAB" = "orange"),
name = "Variables",
labels = c("ConfHI", "HAB"))
dist_BG <- readRDS("dist_BG_int.RData") # BG Sim Matrix
dist_BG <- readRDS("dist_BG_int.RData") # BG Sim Matrix
dist_FG <- readRDS("dist_FG_int.RData") # FG Sim Matrix
dist_SD <- readRDS("dist_SD_int.RData") # SD Sim Matrix
ILV_mat <-readRDS("ILV_mat_int.RData") # Age and Sex Matrices
kov <- readRDS("kov_int.RDS")  # Home range overlap
nxn <- readRDS("nxn_int.RData") # Association Matrix
View(ILV_mat)
ILV_mat[[1]]
View(dist_BG)
dist_BG[[1]]
View(nxn)
nxn[[1]]
list_years_int <- readRDS("list_years_int.RData") # (1995-2000)/(2001-2006)/(2007-20012)
list_years <- readRDS("list_years.RData") # (1998-2004)/(2005-2014)
list_years <- readRDS("list_years.RData") # (1998-2004)/(2005-2014)
list_years_int <- readRDS("list_years_int.RData") # (1995-2000)/(2001-2006)/(2007-20012)
# Extract specific columns from each data frame in list_years
aux_data <- function(list_years) {
aux <- lapply(list_years, function(df) {
data.frame(Code = df$Code,
Behaviors = df$Behaviors,
HumanInteraction = df$HumanInteraction,
ConfHI = df$ConfHI)})
# Add the 'Foraging' variable to each data frame in the 'aux' list
aux <- lapply(aux, function(df) {
df$Foraging <- "Other"
df$Foraging[grepl(pattern = 'Feed', x = df$Behaviors, ignore.case = FALSE)] <- "Feed"
df
})
return(aux)
}
aux <- aux_data(list_years)
aux_int <- aux_data(list_years_int)
# Categorize ID to Foraging
ID_forg <- function(aux_data) {
IDbehav <- lapply(aux_data, function(df) {
df <- table(df$Code, df$Foraging)
df <- as.data.frame(df, stringsAsFactors = FALSE)
df <- df[, c(1, 3)]
colnames(df) <- c("Code", "Forg_Freq")
df <- aggregate(. ~ Code, data = df, sum)
df
})
return(IDbehav)
}
IDbehav <- ID_forg(aux)
IDbehav_int <- ID_forg(aux_int)
# Separate HI Behaviors
#' BG = Beg: F, G
#' SD = Scavenge and Depredation: B, C, D, E
#' FG = Fixed Gear Interaction: P
# Change the code using ifelse statements
subset_HI <- function(aux_data) {
for (i in seq_along(aux_data)) {
aux_data[[i]]$DiffHI <- ifelse(aux_data[[i]]$ConfHI %in% c("F", "G"), "BG",
ifelse(aux_data[[i]]$ConfHI %in% c("B", "C", "D", "E", "A"), "SD",
ifelse(aux_data[[i]]$ConfHI %in% c("P"), "FG", "None")))
}
return(aux_data)  # Return the modified list of data frames
}
aux <- subset_HI(aux)
aux_int <- subset_HI(aux_int)
# Categorize DiffHI to IDs
diff_raw <- function(aux_data) {
rawHI_diff <- lapply(aux_data, function(df) {
table_df <- as.data.frame(table(df$Code, df$DiffHI))
colnames(table_df) <- c("Code", "DiffHI", "Freq")
return(table_df)
})}
rawHI_diff <- diff_raw(aux)
rawHI_diff_int <- diff_raw(aux_int)
# Create a frequency count for each HI behavior
get_IDHI <- function(HI, IDbehav_data, rawHI_diff_data) {
lapply(seq_along(IDbehav_data), function(i) {
df <- IDbehav_data[[i]]
HI_freq <- rawHI_diff_data[[i]]$Freq[rawHI_diff_data[[i]]$DiffHI == HI]
df$HI <- HI_freq[match(df$Code, rawHI_diff_data[[i]]$Code)]
colnames(df) <- c("Code", "Foraging", "HI")
df
})
}
# Two period data
IDbehav_BG <- get_IDHI("BG", IDbehav, rawHI_diff)
View(IDbehav_BG)
IDbehav_BG[[1]]
IDbehav_BG[[2]]
IDbehav_FG <- get_IDHI("FG", IDbehav, rawHI_diff)
IDbehav_SD <- get_IDHI("SD", IDbehav, rawHI_diff)
# Three period data
IDbehav_BG_int <- get_IDHI("BG", IDbehav_int, rawHI_diff_int)
IDbehav_FG_int <- get_IDHI("FG", IDbehav_int, rawHI_diff_int)
IDbehav_SD_int <- get_IDHI("SD", IDbehav_int, rawHI_diff_int)
# Clump all the HI behaviors together
clump_behav <- function(aux_data) {
for (i in seq_along(aux_data)) {
aux_data[[i]]$ConfHI <- ifelse(aux_data[[i]]$ConfHI != "0", 1, 0)}
# Categorize ConfHI to IDs
rawHI <- lapply(aux_data, function(df) {
# Sum up the frequencies of HI by code
aggregated_df <- aggregate(ConfHI ~ Code, data = df, sum)
unique_codes_df <- data.frame(Code = unique(df$Code))
# Merge the unique codes data frame with the aggregated data frame
merged_df <- merge(unique_codes_df, aggregated_df, by = "Code", all.x = TRUE)
# Fill missing Freq values (if any) with 0
merged_df$ConfHI[is.na(merged_df$ConfHI)] <- 0
return(merged_df)
})
return(rawHI)
}
rawHI <- clump_behav(aux)
rawHI_int <- clump_behav(aux_int)
# Get HI Freq
create_IDbehav_HI <- function(IDbehav_data, rawHI_data){
IDbehav_HI <- lapply(seq_along(IDbehav_data), function(i) {
df <- IDbehav_data[[i]]
df$HI <- rawHI_data[[i]]$ConfHI
colnames(df) <- c("Code", "Foraging", "HI")
df
})
return(IDbehav_HI)
}
IDbehav_HI <- create_IDbehav_HI(IDbehav, rawHI)
IDbehav_HI_int <- create_IDbehav_HI(IDbehav_int, rawHI_int)
# Proportion of time Foraging spent in HI
Prop_HI <- function(IDbehav) {
lapply(seq_along(IDbehav), function(i) {
df <- IDbehav[[i]]
df$HIprop <- as.numeric(df$HI) / as.numeric(df$Foraging)
df$HIprop[is.na(df$HIprop)] <- 0
# Keep only 'Code' and 'HIprop' columns
df <- df[, c('Code', 'HIprop')]
df
})
}
# Two period data
prob_HI <- Prop_HI(IDbehav_HI)
prob_BG <- Prop_HI(IDbehav_BG)
prob_SD <- Prop_HI(IDbehav_SD)
prob_FG <- Prop_HI(IDbehav_FG)
# Three period data
prob_HI_int <- Prop_HI(IDbehav_HI_int)
prob_BG_int <- Prop_HI(IDbehav_BG_int)
prob_SD_int <- Prop_HI(IDbehav_SD_int)
prob_FG_int <- Prop_HI(IDbehav_FG_int)
View(prob_HI)
prob_HI[[1]]
nxn <- readRDS("nxn.RData") # association matrix of list_years
nxn_int <- readRDS("nxn_int.RData") # association matrix of list_years_int
# Order data
order_rows <- rownames(nxn[[1]])
order_cols <- colnames(nxn[[1]])
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function(df) df[order_rows, "Code"])
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function(df) df[order_rows, ])
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function(df) df[df$Code %in% order_rows, ])
Prop_HI <- lapply(Prop_HI, function(df) df[order_rows, ])
# Check the class of each element in Prop_HI
sapply(Prop_HI, class)
# Check the structure of order_rows
str(order_rows)
# Check the structure of the first data frame in Prop_HI
str(Prop_HI[[1]])
Prop_HI=prob_HI
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function(df) df[df$Code %in% order_rows, ])
Prop_HI=prob_HI
# Apply the order to each matrix in the list
Prop_HI$Code <- lapply(Prop_HI, function (df) df$Code[match(order_rows, df$Code)])
View(Prop_HI)
Prop_HI=prob_HI
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function (df) df$Code[match(order_rows, df$Code)])
View(Prop_HI)
Prop_HI=prob_HI
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function (df) {
df$Code <- df$Code[match(order_rows, df$Code)]
return(df)})
View(Prop_HI)
Prop_HI[[1]]
Prop_HI[[2]]
# Dissimilarity of HI proportion among individual dolphins, using Euclidean distance
dis_matr <- function(Prop_HI) {
# Order data
order_rows <- rownames(nxn[[1]])
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function (df) {
df$Code <- df$Code[match(order_rows, df$Code)]
return(df)})
# Create matrix
dissimilarity_HI <- list()
for (i in seq_along(Prop_HI)) {
fake_HIprop <- Prop_HI[[i]]$HIprop
dissimilarity_HI[[i]] <- as.matrix(dist(matrix(fake_HIprop), method = "euclidean"))
}
return(dissimilarity_HI)
}
# Two period data
dist_HI <- dis_matr(prob_HI)
dist_BG <- dis_matr(prob_BG)
dist_SD <- dis_matr(prob_SD)
dist_FG <- dis_matr(prob_FG)
saveRDS(dist_HI, "dist_HI.RData")
saveRDS(dist_BG, "dist_BG.RData")
saveRDS(dist_SD, "dist_SD.RData")
saveRDS(dist_FG, "dist_FG.RData")
# Three period data
dist_HI_int <- dis_matr(prob_HI_int)
# Dissimilarity of HI proportion among individual dolphins, using Euclidean distance
dis_matr <- function(Prop_HI, nxn) {
# Order data
order_rows <- rownames(nxn[[1]])
# Apply the order to each matrix in the list
Prop_HI <- lapply(Prop_HI, function (df) {
df$Code <- df$Code[match(order_rows, df$Code)]
return(df)})
# Create matrix
dissimilarity_HI <- list()
for (i in seq_along(Prop_HI)) {
fake_HIprop <- Prop_HI[[i]]$HIprop
dissimilarity_HI[[i]] <- as.matrix(dist(matrix(fake_HIprop), method = "euclidean"))
}
return(dissimilarity_HI)
}
# Three period data
dist_HI_int <- dis_matr(prob_HI_int, nxn_int)
dist_BG_int <- dis_matr(prob_BG_int, nxn_int)
dist_SD_int <- dis_matr(prob_SD_int, nxn_int)
dist_FG_int <- dis_matr(prob_FG_int, nxn_int)
saveRDS(dist_HI_int, "dist_HI_int.RData")
saveRDS(dist_BG_int, "dist_BG_int.RData")
saveRDS(dist_SD_int, "dist_SD_int.RData")
saveRDS(dist_FG_int, "dist_FG_int.RData")
dist_BG <- readRDS("dist_BG.RData") # BG Sim Matrix
dist_FG <- readRDS("dist_FG.RData") # FG Sim Matrix
dist_SD <- readRDS("dist_SD.RData") # SD Sim Matrix
ILV_mat <-readRDS("ILV_mat.RData") # Age and Sex Matrices
kov <- readRDS("kov.RDS")  # Home range overlap
nxn <- readRDS("nxn.RData") # Association Matrix
# Prepare random effect for MCMC
num_nodes <- lapply(nxn, function(df) dim(df)[1])
node_names <- lapply(nxn, function(df) colnames(df))
# Separate IDs into i and j
node_ids_i <- lapply(num_nodes, function(df) matrix(rep(1:df, each = df), nrow = df, ncol = df))
node_ids_j <- lapply(node_ids_i, function(df) t(df))
# Format data
upper_tri <- lapply(nxn, function(df) upper.tri(df, diag = TRUE))
edge_nxn <- abind(lapply(nxn, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
HAB_data <- cbind(c(edge_nxn[,1], edge_nxn[,2]), c(rep(0, nrow(edge_nxn)), rep(1, nrow(edge_nxn)))) # Two
HAB_data <- cbind(c(edge_nxn[,1], edge_nxn[,2], edge_nxn[,3]), c(rep(1, nrow(edge_nxn)), rep(2, nrow(edge_nxn)), rep(3, nrow(edge_nxn)))) # Three
HAB_data <- cbind(c(edge_nxn[,1], edge_nxn[,2]), c(rep(0, nrow(edge_nxn)), rep(1, nrow(edge_nxn)))) # Two
BG <- abind(lapply(dist_BG, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
FG <- abind(lapply(dist_FG, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
SD <- abind(lapply(dist_SD, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
#SE <- abind(lapply(SE_list, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
one <- lapply(seq_along(node_ids_i), function(i) factor(as.vector(node_names[[i]][node_ids_i[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
two <- lapply(seq_along(node_ids_j), function(i) factor(as.vector(node_names[[i]][node_ids_j[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
# Put data into a dataframe
period = 2
df_list = data.frame(edge_weight = HAB_data[, 1],
HAB = HAB_data[, 2],
HRO = unlist(lapply(kov, function (df) df[upper.tri(df, diag = TRUE)])),
sex_similarity = rep(ILV_mat[[1]][upper.tri(ILV_mat[[1]], diag = TRUE)], period),
age_difference = rep(ILV_mat[[2]][upper.tri(ILV_mat[[2]], diag = TRUE)], period),
#GR = gr_list,
#HI_differences = c(HI[,c(1:period)]),
BG_differences = c(BG[,c(1:period)]),
FG_differences = c(FG[,c(1:period)]),
SD_differences = c(SD[,c(1:period)]),
#Obs.Err = c(SE[,1], SE[,2]),
node_id_1 = unlist(one),
node_id_2 = unlist(two))
fit_mcmc.1 <- MCMCglmm(edge_weight ~ BG_differences * HAB + FG_differences * HAB + SD_differences * HAB +
HRO + age_difference + sex_similarity,
random=~mm(node_id_1 + node_id_2), data = df_list, nitt = 20000)
summary(fit_mcmc.1)
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", #"HI_differences", "HI_differences:HAB",
"HAB", "BG_differences:HAB", "HAB:FG_differences", "HAB:SD_differences",
"age_difference", "sex_similarity", "HRO"))
# Extract Posteriors
posterior <- fit_mcmc.1$Sol
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", #"HI_differences", "HI_differences:HAB",
"HAB", "BG_differences:HAB", "HAB:FG_differences", "HAB:SD_differences",
"age_difference", "sex_similarity", "HRO"))
# Read in social association matrix and listed data
## Two period data
dist_HI <- readRDS("dist_HI.RData") # HI Sim Matrix
HI <- abind(lapply(dist_HI, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
df_list = data.frame(edge_weight = HAB_data[, 1],
HAB = HAB_data[, 2],
HRO = unlist(lapply(kov, function (df) df[upper.tri(df, diag = TRUE)])),
sex_similarity = rep(ILV_mat[[1]][upper.tri(ILV_mat[[1]], diag = TRUE)], period),
age_difference = rep(ILV_mat[[2]][upper.tri(ILV_mat[[2]], diag = TRUE)], period),
#GR = gr_list,
HI_differences = c(HI[,c(1:period)]),
# BG_differences = c(BG[,c(1:period)]),
# FG_differences = c(FG[,c(1:period)]),
# SD_differences = c(SD[,c(1:period)]),
#Obs.Err = c(SE[,1], SE[,2]),
node_id_1 = unlist(one),
node_id_2 = unlist(two))
View(df_list)
# Multimembership models in MCMCglmm
## HI Behavior Combined Two Year Period ##
fit_mcmc.1 <- MCMCglmm(edge_weight ~ HI_differences * HAB + HRO + age_difference + sex_similarity,
random=~mm(node_id_1 + node_id_2), data = df_list, nitt = 20000)
summary(fit_mcmc.1)
# Extract Posteriors
posterior <- fit_mcmc.1$Sol
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", "HI_differences", "HI_differences:HAB",
"HAB", "age_difference", "sex_similarity", "HRO"))
## Three period data
dist_HI <- readRDS("dist_HI_int.RData") # HI Sim Matrix
ILV_mat <-readRDS("ILV_mat_int.RData") # Age and Sex Matrices
kov <- readRDS("kov_int.RDS")  # Home range overlap
nxn <- readRDS("nxn_int.RData") # Association Matrix
# Prepare random effect for MCMC
num_nodes <- lapply(nxn, function(df) dim(df)[1])
node_names <- lapply(nxn, function(df) colnames(df))
# Separate IDs into i and j
node_ids_i <- lapply(num_nodes, function(df) matrix(rep(1:df, each = df), nrow = df, ncol = df))
node_ids_j <- lapply(node_ids_i, function(df) t(df))
# Format data
upper_tri <- lapply(nxn, function(df) upper.tri(df, diag = TRUE))
edge_nxn <- abind(lapply(nxn, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
HAB_data <- cbind(c(edge_nxn[,1], edge_nxn[,2], edge_nxn[,3]), c(rep(1, nrow(edge_nxn)), rep(2, nrow(edge_nxn)), rep(3, nrow(edge_nxn)))) # Three
HI <- abind(lapply(dist_HI, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
# Format data
period = 3
#SE <- abind(lapply(SE_list, function(mat) mat[upper.tri(mat, diag = TRUE)]), along = 2)
one <- lapply(seq_along(node_ids_i), function(i) factor(as.vector(node_names[[i]][node_ids_i[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
two <- lapply(seq_along(node_ids_j), function(i) factor(as.vector(node_names[[i]][node_ids_j[[i]][upper_tri[[i]]]]), levels = node_names[[i]]))
# Put data into a dataframe
df_list = data.frame(edge_weight = HAB_data[, 1],
HAB = HAB_data[, 2],
HRO = unlist(lapply(kov, function (df) df[upper.tri(df, diag = TRUE)])),
sex_similarity = rep(ILV_mat[[1]][upper.tri(ILV_mat[[1]], diag = TRUE)], period),
age_difference = rep(ILV_mat[[2]][upper.tri(ILV_mat[[2]], diag = TRUE)], period),
#GR = gr_list,
HI_differences = c(HI[,c(1:period)]),
# BG_differences = c(BG[,c(1:period)]),
# FG_differences = c(FG[,c(1:period)]),
# SD_differences = c(SD[,c(1:period)]),
#Obs.Err = c(SE[,1], SE[,2]),
node_id_1 = unlist(one),
node_id_2 = unlist(two))
View(df_list)
## HI Behavior Combined Three Year Period ##
fit_mcmc.2 <- MCMCglmm(edge_weight ~ HI_differences * HAB + HRO + age_difference + sex_similarity,
random=~mm(node_id_1 + node_id_2), data = df_list, nitt = 20000)
summary(fit_mcmc.2)
# Check for model convergence
plot(fit_mcmc.2$Sol)
# Check for model convergence
plot(fit_mcmc.2$Sol)
# Extract Posteriors
posterior <- fit_mcmc.2$Sol
# Plot the posterior distribution
mcmc_intervals(posterior, pars = c("(Intercept)", "HI_differences", "HI_differences:HAB",
"HAB", "age_difference", "sex_similarity", "HRO"))
